import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Mic, MicOff, Volume2, VolumeX, Settings, PhoneOff, Loader2 } from 'lucide-react';
import { Button } from '../ui/button';

// WebSocketæ¶ˆæ¯ç±»å‹å®šä¹‰
interface WebSocketMessage {
  type: string;
  text?: string;
  emotion?: EmotionMetrics;
  duration?: number;
  message?: string;
}

// è¯­éŸ³çŠ¶æ€æšä¸¾
enum VoiceState {
  IDLE = 'idle',           // ç©ºé—²
  LISTENING = 'listening', // æ­£åœ¨è†å¬ç”¨æˆ·
  THINKING = 'thinking',   // AIæ€è€ƒä¸­
  SPEAKING = 'speaking'    // AIè¯´è¯ä¸­
}

// æƒ…ç»ªæŒ‡æ ‡ç±»å‹
interface EmotionMetrics {
  pleasantness: number;  // æ„‰æ‚¦åº¦ 0-100
  energy: number;        // èƒ½é‡å€¼ 0-100
  clarity: number;       // æ¸…æ™°åº¦ 0-100
}

// å¯¹è¯æ¶ˆæ¯ç±»å‹
interface VoiceMessage {
  id: string;
  type: 'user' | 'ai';
  text: string;
  timestamp: Date;
  duration?: number;     // è¯­éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
  emotion?: EmotionMetrics;
}

interface DoubaoRealtimeVoiceProps {
  sessionId: string;
  onSessionEnd: () => void;
  className?: string;
}

export const DoubaoRealtimeVoice: React.FC<DoubaoRealtimeVoiceProps> = ({
  sessionId,
  onSessionEnd,
  className = ''
}) => {
  // çŠ¶æ€ç®¡ç†
  const [voiceState, setVoiceState] = useState<VoiceState>(VoiceState.IDLE);
  const [isConnected, setIsConnected] = useState(false);
  const [isAudioInitialized, setIsAudioInitialized] = useState(false);
  const [messages, setMessages] = useState<VoiceMessage[]>([]);
  const [currentEmotion, setCurrentEmotion] = useState<EmotionMetrics>({
    pleasantness: 75,
    energy: 65,
    clarity: 80
  });
  
  // éŸ³é¢‘æ§åˆ¶çŠ¶æ€
  const [isMuted, setIsMuted] = useState(false);
  const [volume, setVolume] = useState(80);
  const [selectedVoice, setSelectedVoice] = useState('zh-CN-XiaoxiaoNeural');
  
  // è®¡æ—¶å™¨çŠ¶æ€
  const [sessionDuration, setSessionDuration] = useState(0);
  const [recordingDuration, setRecordingDuration] = useState(0);
  
  // Refs
  const wsRef = useRef<WebSocket | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  
  // åŠ¨ç”»æ•°æ®
  const [waveformData, setWaveformData] = useState<number[]>(new Array(32).fill(0));
  const [isWaveAnimating, setIsWaveAnimating] = useState(false);

  // åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
  const initializeAudio = useCallback(async () => {
    try {
      audioContextRef.current = new AudioContext();
      analyserRef.current = audioContextRef.current.createAnalyser();
      analyserRef.current.fftSize = 64;
    } catch (error) {
      console.error('éŸ³é¢‘åˆå§‹åŒ–å¤±è´¥:', error);
    }
  }, []);

  // åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿï¼ˆåŒ…å«éº¦å…‹é£æƒé™ï¼‰
  const initializeAudioSystem = useCallback(async () => {
    try {
      console.log('ğŸ¤ å¼€å§‹åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ...');
      
      // 1. åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
      await initializeAudio();
      
      // 2. è¯·æ±‚éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log('âœ… éº¦å…‹é£æƒé™è·å–æˆåŠŸ');
      
      // 3. åœæ­¢ä¸´æ—¶æµï¼ˆä»…ç”¨äºæƒé™éªŒè¯ï¼‰
      stream.getTracks().forEach(track => track.stop());
      
      // 4. æ ‡è®°éŸ³é¢‘ç³»ç»Ÿå·²åˆå§‹åŒ–
      setIsAudioInitialized(true);
      console.log('âœ… éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ');
      
    } catch (error) {
      console.error('âŒ éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥:', error);
      alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æµè§ˆå™¨æƒé™è®¾ç½®');
    }
  }, [initializeAudio]);

  // WebSocketè¿æ¥
  const connectWebSocket = useCallback(() => {
    const wsUrl = `ws://localhost:8000/api/v1/ws/realtime-voice/${sessionId}`;
    wsRef.current = new WebSocket(wsUrl);
    
    wsRef.current.onopen = () => {
      setIsConnected(true);
      setVoiceState(VoiceState.IDLE);
      console.log('ğŸ”— å®æ—¶è¯­éŸ³è¿æ¥å·²å»ºç«‹');
    };
    
    wsRef.current.onmessage = (event) => {
      const data = JSON.parse(event.data);
      handleWebSocketMessage(data);
    };
    
    wsRef.current.onclose = () => {
      setIsConnected(false);
      setVoiceState(VoiceState.IDLE);
      console.log('ğŸ”Œ å®æ—¶è¯­éŸ³è¿æ¥å·²æ–­å¼€');
    };
    
    wsRef.current.onerror = (error) => {
      console.error('WebSocketé”™è¯¯:', error);
    };
  }, [sessionId]);

  // å¤„ç†WebSocketæ¶ˆæ¯
  const handleWebSocketMessage = (data: WebSocketMessage) => {
    console.log('ğŸ“¨ æ”¶åˆ°WebSocketæ¶ˆæ¯:', data);
    
    switch (data.type) {
      case 'ai_response':
        console.log('ğŸ¤– æ”¶åˆ°AIå›å¤:', data.text);
        setMessages(prev => [...prev, {
          id: Date.now().toString(),
          type: 'ai',
          text: data.text || '',
          timestamp: new Date(),
          emotion: data.emotion
        }]);
        setVoiceState(VoiceState.SPEAKING);
        break;
        
      case 'transcription':
        console.log('ğŸ“ æ”¶åˆ°è¯­éŸ³è½¬å½•:', data.text);
        setMessages(prev => [...prev, {
          id: Date.now().toString(),
          type: 'user',
          text: data.text || '',
          timestamp: new Date(),
          duration: data.duration
        }]);
        setVoiceState(VoiceState.THINKING);
        break;
        
      case 'emotion_update':
        console.log('ğŸ˜Š æƒ…æ„Ÿæ•°æ®æ›´æ–°:', data.emotion);
        if (data.emotion) {
          setCurrentEmotion(data.emotion);
        }
        break;
        
      case 'audio_start':
        console.log('ğŸ”Š AIå¼€å§‹è¯­éŸ³æ’­æ”¾');
        setVoiceState(VoiceState.SPEAKING);
        setIsWaveAnimating(true);
        break;
        
      case 'audio_end':
        console.log('ğŸ”‡ AIè¯­éŸ³æ’­æ”¾ç»“æŸ');
        setVoiceState(VoiceState.IDLE);
        setIsWaveAnimating(false);
        break;
        
      case 'error':
        console.error('âŒ æœåŠ¡å™¨é”™è¯¯:', data.message);
        setVoiceState(VoiceState.IDLE);
        alert(`æœåŠ¡å™¨é”™è¯¯: ${data.message || 'æœªçŸ¥é”™è¯¯'}`);
        break;
        
      default:
        console.log('â“ æœªçŸ¥æ¶ˆæ¯ç±»å‹:', data.type);
        break;
    }
  };

  // åˆ‡æ¢å½•éŸ³çŠ¶æ€
  const toggleRecording = async () => {
    if (!isConnected) {
      console.log('âŒ WebSocketæœªè¿æ¥');
      return;
    }
    
    if (!isAudioInitialized) {
      console.log('âŒ éŸ³é¢‘ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆç‚¹å‡»åˆå§‹åŒ–éŸ³é¢‘');
      alert('è¯·å…ˆç‚¹å‡»"åˆå§‹åŒ–éŸ³é¢‘"æŒ‰é’®');
      return;
    }
    
    if (voiceState === VoiceState.LISTENING) {
      // æ­£åœ¨å½•éŸ³ï¼Œåœæ­¢å½•éŸ³
      stopRecording();
    } else if (voiceState === VoiceState.IDLE) {
      // ç©ºé—²çŠ¶æ€ï¼Œå¼€å§‹å½•éŸ³
      await startRecording();
    }
  };

  // å¼€å§‹å½•éŸ³
  const startRecording = async () => {
    if (!isConnected) return;
    
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // è¿æ¥éŸ³é¢‘åˆ†æå™¨
      if (audioContextRef.current && analyserRef.current) {
        const source = audioContextRef.current.createMediaStreamSource(stream);
        source.connect(analyserRef.current);
        startWaveformAnalysis();
      }
      
      mediaRecorderRef.current = new MediaRecorder(stream);
      const audioChunks: Blob[] = [];
      
      mediaRecorderRef.current.ondataavailable = (event) => {
        audioChunks.push(event.data);
      };
      
      mediaRecorderRef.current.onstop = () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        sendAudioToServer(audioBlob);
      };
      
      mediaRecorderRef.current.start();
      setVoiceState(VoiceState.LISTENING);
      setIsWaveAnimating(true);
      console.log('ğŸ¤ å¼€å§‹å½•éŸ³...');
      
    } catch (error) {
      console.error('å½•éŸ³å¯åŠ¨å¤±è´¥:', error);
      alert('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
    }
  };

  // åœæ­¢å½•éŸ³
  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
      setVoiceState(VoiceState.THINKING);
      setIsWaveAnimating(false);
      console.log('ğŸ›‘ åœæ­¢å½•éŸ³ï¼Œæ­£åœ¨å¤„ç†...');
    }
  };

  // å‘é€éŸ³é¢‘åˆ°æœåŠ¡å™¨
  const sendAudioToServer = (audioBlob: Blob) => {
    console.log('ğŸ“¤ å‡†å¤‡å‘é€éŸ³é¢‘æ•°æ®ï¼Œå¤§å°:', audioBlob.size, 'bytes');
    
    if (!wsRef.current) {
      console.error('âŒ WebSocketè¿æ¥æœªå»ºç«‹');
      return;
    }
    
    if (wsRef.current.readyState !== WebSocket.OPEN) {
      console.error('âŒ WebSocketè¿æ¥çŠ¶æ€å¼‚å¸¸:', wsRef.current.readyState);
      return;
    }
    
    const reader = new FileReader();
    reader.onload = () => {
      try {
        const base64Audio = reader.result as string;
        const audioData = base64Audio.split(',')[1];
        
        const message = {
          type: 'audio_data',
          audio: audioData,
          voice: selectedVoice,
          session_id: sessionId,
          timestamp: new Date().toISOString()
        };
        
        console.log('ğŸ“¤ å‘é€éŸ³é¢‘æ•°æ®åˆ°æœåŠ¡å™¨:', {
          type: message.type,
          audioSize: audioData.length,
          voice: message.voice,
          sessionId: message.session_id
        });
        
        wsRef.current?.send(JSON.stringify(message));
        console.log('âœ… éŸ³é¢‘æ•°æ®å‘é€æˆåŠŸ');
        
      } catch (error) {
        console.error('âŒ å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥:', error);
        setVoiceState(VoiceState.IDLE);
      }
    };
    
    reader.onerror = () => {
      console.error('âŒ è¯»å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥');
      setVoiceState(VoiceState.IDLE);
    };
    
    reader.readAsDataURL(audioBlob);
  };

  // å®æ—¶æ³¢å½¢åˆ†æ
  const startWaveformAnalysis = () => {
    if (!analyserRef.current) return;
    
    const bufferLength = analyserRef.current.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    
    const updateWaveform = () => {
      if (!analyserRef.current || !isWaveAnimating) return;
      
      analyserRef.current.getByteFrequencyData(dataArray);
      const normalizedData = Array.from(dataArray).map(value => value / 255);
      setWaveformData(normalizedData.slice(0, 32));
      
      requestAnimationFrame(updateWaveform);
    };
    
    updateWaveform();
  };

  // æ ¼å¼åŒ–æ—¶é—´
  const formatTime = (seconds: number) => {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes.toString().padStart(2, '0')}:${remainingSeconds.toString().padStart(2, '0')}`;
  };

  // è·å–çŠ¶æ€æ˜¾ç¤ºæ–‡æœ¬
  const getStateText = () => {
    switch (voiceState) {
      case VoiceState.IDLE: return 'å‡†å¤‡å°±ç»ª';
      case VoiceState.LISTENING: return 'æ­£åœ¨è†å¬...';
      case VoiceState.THINKING: return 'AIæ€è€ƒä¸­...';
      case VoiceState.SPEAKING: return 'AIæ­£åœ¨å›ç­”...';
      default: return 'æœªçŸ¥çŠ¶æ€';
    }
  };

  // è·å–çŠ¶æ€é¢œè‰²
  const getStateColor = () => {
    switch (voiceState) {
      case VoiceState.IDLE: return 'text-green-500';
      case VoiceState.LISTENING: return 'text-blue-500';
      case VoiceState.THINKING: return 'text-yellow-500';
      case VoiceState.SPEAKING: return 'text-purple-500';
      default: return 'text-gray-500';
    }
  };

  // ç”Ÿå‘½å‘¨æœŸ
  useEffect(() => {
    initializeAudio();
    connectWebSocket();
    
    const sessionTimer = setInterval(() => {
      setSessionDuration(prev => prev + 1);
    }, 1000);
    
    return () => {
      clearInterval(sessionTimer);
      wsRef.current?.close();
      audioContextRef.current?.close();
    };
  }, [initializeAudio, connectWebSocket]);

  // å½•éŸ³è®¡æ—¶å™¨
  useEffect(() => {
    let recordingTimer: NodeJS.Timeout;
    
    if (voiceState === VoiceState.LISTENING) {
      setRecordingDuration(0);
      recordingTimer = setInterval(() => {
        setRecordingDuration(prev => prev + 1);
      }, 1000);
    }
    
    return () => {
      if (recordingTimer) clearInterval(recordingTimer);
    };
  }, [voiceState]);

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  return (
    <div className={`h-screen flex flex-col bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900 text-white ${className}`}>
      {/* å¤´éƒ¨çŠ¶æ€æ  */}
      <div className="flex-none px-6 py-4 bg-black/20 backdrop-blur-sm">
        <div className="flex items-center justify-between">
          <div className="flex items-center space-x-3">
            <div className={`w-3 h-3 rounded-full ${isConnected ? 'bg-green-500 animate-pulse' : 'bg-red-500'}`} />
            <span className={`font-medium ${getStateColor()}`}>
              {getStateText()}
            </span>
          </div>
          
          <div className="flex items-center space-x-4 text-sm text-gray-300">
            <span>ä¼šè¯æ—¶é•¿: {formatTime(sessionDuration)}</span>
            {voiceState === VoiceState.LISTENING && (
              <span className="text-blue-400">å½•éŸ³: {formatTime(recordingDuration)}</span>
            )}
          </div>
        </div>
      </div>

      {/* ä¸»å†…å®¹åŒºåŸŸ */}
      <div className="flex-1 flex flex-col overflow-hidden">
        {/* æ³¢å½¢å¯è§†åŒ–åŒºåŸŸ */}
        <div className="flex-none h-32 flex items-center justify-center bg-black/10 backdrop-blur-sm">
          <div className="flex items-end space-x-1 h-20">
            {waveformData.map((value, index) => (
              <div
                key={index}
                className={`w-2 bg-gradient-to-t transition-all duration-100 ${
                  isWaveAnimating 
                    ? voiceState === VoiceState.LISTENING 
                      ? 'from-blue-500 to-blue-300' 
                      : 'from-purple-500 to-purple-300'
                    : 'from-gray-600 to-gray-400'
                }`}
                style={{ 
                  height: `${Math.max(4, value * 80)}px`,
                  opacity: isWaveAnimating ? 0.8 + value * 0.2 : 0.3
                }}
              />
            ))}
          </div>
        </div>

        {/* æƒ…ç»ªæŒ‡æ ‡æ¡ */}
        <div className="flex-none px-6 py-3 bg-black/10 backdrop-blur-sm">
          <div className="grid grid-cols-3 gap-4 text-xs">
            <div>
              <div className="flex justify-between mb-1">
                <span>æ„‰æ‚¦åº¦</span>
                <span>{currentEmotion.pleasantness}%</span>
              </div>
              <div className="w-full h-2 bg-gray-700 rounded-full overflow-hidden">
                <div 
                  className="h-full bg-gradient-to-r from-green-500 to-green-400 transition-all duration-500"
                  style={{ width: `${currentEmotion.pleasantness}%` }}
                />
              </div>
            </div>
            
            <div>
              <div className="flex justify-between mb-1">
                <span>èƒ½é‡å€¼</span>
                <span>{currentEmotion.energy}%</span>
              </div>
              <div className="w-full h-2 bg-gray-700 rounded-full overflow-hidden">
                <div 
                  className="h-full bg-gradient-to-r from-orange-500 to-orange-400 transition-all duration-500"
                  style={{ width: `${currentEmotion.energy}%` }}
                />
              </div>
            </div>
            
            <div>
              <div className="flex justify-between mb-1">
                <span>æ¸…æ™°åº¦</span>
                <span>{currentEmotion.clarity}%</span>
              </div>
              <div className="w-full h-2 bg-gray-700 rounded-full overflow-hidden">
                <div 
                  className="h-full bg-gradient-to-r from-blue-500 to-blue-400 transition-all duration-500"
                  style={{ width: `${currentEmotion.clarity}%` }}
                />
              </div>
            </div>
          </div>
        </div>

        {/* å¯¹è¯æ¶ˆæ¯åŒºåŸŸ */}
        <div className="flex-1 overflow-y-auto px-6 py-4 space-y-4">
          {messages.length === 0 ? (
            <div className="flex items-center justify-center h-full text-gray-400">
              <div className="text-center">
                <Mic className="w-16 h-16 mx-auto mb-4 opacity-50" />
                <p style={{ fontSize: '1.4rem', fontWeight: 'bold', color: '#ffffff', margin: '1rem 0 0.5rem' }}>
                  å®æ—¶è¯­éŸ³é¢è¯•
                </p>
                {!isAudioInitialized ? (
                  <div className="space-y-4">
                    <p className="text-sm text-yellow-400">é¦–æ¬¡ä½¿ç”¨éœ€è¦åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ</p>
                    <Button
                      onClick={initializeAudioSystem}
                      className="px-6 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-lg"
                    >
                      ğŸ¤ åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
                    </Button>
                    <p className="text-xs text-gray-500">ç‚¹å‡»åå°†è·å–éº¦å…‹é£æƒé™ï¼Œç”¨äºè¯­éŸ³è¯†åˆ«</p>
                  </div>
                ) : (
                  <p className="text-sm text-green-400">âœ… éŸ³é¢‘ç³»ç»Ÿå·²å°±ç»ªï¼Œç‚¹å‡»éº¦å…‹é£å¼€å§‹å¯¹è¯</p>
                )}
              </div>
            </div>
          ) : (
            messages.map((message) => (
              <div
                key={message.id}
                className={`flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
              >
                <div
                  className={`max-w-xs lg:max-w-md px-4 py-2 rounded-2xl ${
                    message.type === 'user'
                      ? 'bg-blue-600 text-white'
                      : 'bg-gray-700 text-gray-100'
                  }`}
                >
                  <p className="text-sm leading-relaxed">{message.text}</p>
                  <div className="flex items-center justify-between mt-2 text-xs opacity-70">
                    <span>{message.timestamp.toLocaleTimeString()}</span>
                    {message.duration && (
                      <span>{message.duration}s</span>
                    )}
                  </div>
                </div>
              </div>
            ))
          )}
          <div ref={messagesEndRef} />
        </div>
      </div>

      {/* åº•éƒ¨æ§åˆ¶æ  */}
      <div className="flex-none px-6 py-4 bg-black/20 backdrop-blur-sm">
        <div className="flex items-center justify-center space-x-4">
          {/* éº¦å…‹é£ä¸»æŒ‰é’® */}
          <Button
            size="lg"
            disabled={!isConnected}
            className={`w-20 h-20 rounded-full transition-all duration-200 ${
              voiceState === VoiceState.LISTENING
                ? 'bg-red-500 hover:bg-red-600 animate-pulse'
                : 'bg-blue-500 hover:bg-blue-600'
            }`}
            onClick={toggleRecording}
          >
            {voiceState === VoiceState.LISTENING ? (
              <MicOff className="w-8 h-8" />
            ) : voiceState === VoiceState.THINKING ? (
              <Loader2 className="w-8 h-8 animate-spin" />
            ) : (
              <Mic className="w-8 h-8" />
            )}
          </Button>

          {/* éŸ³é‡æ§åˆ¶ */}
          <div className="flex items-center space-x-2">
            <Button
              variant="ghost"
              size="sm"
              onClick={() => setIsMuted(!isMuted)}
              className="text-gray-300 hover:text-white"
            >
              {isMuted ? <VolumeX className="w-5 h-5" /> : <Volume2 className="w-5 h-5" />}
            </Button>
            <input
              type="range"
              min="0"
              max="100"
              value={volume}
              onChange={(e) => setVolume(parseInt(e.target.value))}
              className="w-20 h-2 bg-gray-700 rounded-lg appearance-none slider"
              title="éŸ³é‡è°ƒèŠ‚"
              aria-label="éŸ³é‡è°ƒèŠ‚æ»‘å—"
            />
            <span className="text-xs text-gray-400 w-8">{volume}%</span>
          </div>

          {/* è®¾ç½®æŒ‰é’® */}
          <Button
            variant="ghost"
            size="sm"
            className="text-gray-300 hover:text-white"
          >
            <Settings className="w-5 h-5" />
          </Button>

          {/* ç»“æŸé€šè¯ */}
          <Button
            variant="destructive"
            size="sm"
            onClick={onSessionEnd}
            className="ml-4"
          >
            <PhoneOff className="w-4 h-4 mr-2" />
            ç»“æŸé¢è¯•
          </Button>
        </div>

        {/* è¯­éŸ³é€‰æ‹© */}
        <div className="mt-3 flex justify-center">
          <select
            value={selectedVoice}
            onChange={(e) => setSelectedVoice(e.target.value)}
            className="bg-gray-700 text-white px-3 py-1 rounded text-sm border-none outline-none"
            title="é€‰æ‹©è¯­éŸ³"
            aria-label="è¯­éŸ³é€‰æ‹©å™¨"
          >
            <option value="zh-CN-XiaoxiaoNeural">å°æ™“ - æ¸©æŸ”å¥³å£°</option>
            <option value="zh-CN-YunxiNeural">äº‘å¸Œ - ä¸“ä¸šç”·å£°</option>
            <option value="zh-CN-XiaoyiNeural">å°è‰º - æ´»æ³¼å¥³å£°</option>
            <option value="zh-CN-YunyangNeural">äº‘æ‰¬ - ç¨³é‡ç”·å£°</option>
            <option value="en-US-JennyNeural">Jenny - ç¾å¼è‹±è¯­å¥³å£°</option>
            <option value="en-US-GuyNeural">Guy - ç¾å¼è‹±è¯­ç”·å£°</option>
          </select>
        </div>
      </div>
    </div>
  );
}; 