"""
æ€§èƒ½ç›‘æ§æ¨¡å—
è·Ÿè¸ªåŒæ¨¡å‹æ¶æ„çš„æ€§èƒ½æŒ‡æ ‡å’Œåˆ‡æ¢æƒ…å†µ
å¢å¼ºç‰ˆæœ¬ - ä¿®å¤å†…å­˜æ³„æ¼å’Œèµ„æºç®¡ç†é—®é¢˜
"""

import time
import asyncio
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
from collections import defaultdict, deque
from contextlib import contextmanager
import logging
import json
import gc
from functools import lru_cache, wraps
from dataclasses import dataclass, field
import psutil
import aiofiles
import weakref

logger = logging.getLogger(__name__)

@dataclass
class MetricData:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    total_calls: int = 0
    successful_calls: int = 0
    failed_calls: int = 0
    total_duration: float = 0.0
    min_duration: float = float('inf')
    max_duration: float = 0.0
    avg_duration: float = 0.0
    last_call: Optional[datetime] = None
    error_types: Dict[str, int] = field(default_factory=dict)
    recent_durations: deque = field(default_factory=lambda: deque(maxlen=100))
    created_at: datetime = field(default_factory=datetime.now)  # æ·»åŠ åˆ›å»ºæ—¶é—´

    def is_expired(self, max_age_hours: int = 24) -> bool:
        """æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦è¿‡æœŸ"""
        if not self.last_call:
            return (datetime.now() - self.created_at).total_seconds() > max_age_hours * 3600
        return (datetime.now() - self.last_call).total_seconds() > max_age_hours * 3600

# æ·»åŠ async_timeitè£…é¥°å™¨
def async_timeit(metric_name: str = None, log_slow_threshold: float = 1.0):
    """
    å¼‚æ­¥å‡½æ•°æ€§èƒ½è®¡æ—¶è£…é¥°å™¨
    
    Args:
        metric_name: æŒ‡æ ‡åç§°ï¼Œé»˜è®¤ä½¿ç”¨å‡½æ•°å
        log_slow_threshold: æ…¢è¯·æ±‚é˜ˆå€¼ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡åˆ™è®°å½•è­¦å‘Š
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.perf_counter()
            metric = metric_name or f"{func.__module__}.{func.__name__}"
            
            try:
                # æ‰§è¡ŒåŸå‡½æ•°
                result = await func(*args, **kwargs)
                
                # è®¡ç®—è€—æ—¶
                duration = time.perf_counter() - start_time
                
                # è®°å½•åˆ°æ€§èƒ½ç›‘æ§
                monitor = get_performance_monitor()
                monitor.record_api_latency(metric, duration * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
                
                # æ…¢è¯·æ±‚è­¦å‘Š
                if duration > log_slow_threshold:
                    logger.warning(
                        f"Slow API call detected: {metric}",
                        duration_ms=duration * 1000,
                        threshold_ms=log_slow_threshold * 1000,
                        extra={"metric": metric, "duration_ms": duration * 1000}
                    )
                
                return result
                
            except Exception as e:
                # è®°å½•é”™è¯¯
                duration = time.perf_counter() - start_time
                monitor = get_performance_monitor()
                monitor.record_error(f"error.{metric}", str(e))
                monitor.record_api_latency(metric, duration * 1000)
                
                logger.error(f"API call failed: {metric}", error=str(e))
                raise
                
        return wrapper
    return decorator

# åŒæ­¥å‡½æ•°æ€§èƒ½è®¡æ—¶è£…é¥°å™¨
def timeit(metric_name: str = None, log_slow_threshold: float = 1.0):
    """
    åŒæ­¥å‡½æ•°æ€§èƒ½è®¡æ—¶è£…é¥°å™¨
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.perf_counter()
            metric = metric_name or f"{func.__module__}.{func.__name__}"
            
            try:
                result = func(*args, **kwargs)
                duration = time.perf_counter() - start_time
                
                monitor = get_performance_monitor()
                monitor.record_api_latency(metric, duration * 1000)
                
                if duration > log_slow_threshold:
                    logger.warning(f"Slow call: {metric}", duration_ms=duration * 1000)
                
                return result
                
            except Exception as e:
                duration = time.perf_counter() - start_time
                monitor = get_performance_monitor()
                monitor.record_error(f"error.{metric}", str(e))
                
                logger.error(f"API call failed: {metric}", error=str(e))
                raise
                
        return wrapper
    return decorator

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨ - çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼Œå¢å¼ºå†…å­˜ç®¡ç†"""
    
    def __init__(self, max_history: int = 1000, enable_gc_optimization: bool = True):
        self.max_history = max_history
        self._lock = threading.RLock()  # ä½¿ç”¨å¯é‡å…¥é”
        self._metrics_lock = threading.RLock()
        
        # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®ç»“æ„
        self.metrics: Dict[str, MetricData] = {}
        
        # åˆ‡æ¢è®°å½•
        self.switch_history = deque(maxlen=max_history)
        
        # å®æ—¶æŒ‡æ ‡
        self.current_provider = None
        self.last_switch_time = None
        self.switch_count = 0
        
        # æ€§èƒ½é˜ˆå€¼ - é’ˆå¯¹è±†åŒ…å®æ—¶è¯­éŸ³ä¼˜åŒ–
        self.thresholds = {
            "slow_response_ms": 3000,  # æ…¢å“åº”é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
            "realtime_voice_ms": 500,  # å®æ—¶è¯­éŸ³å“åº”é˜ˆå€¼ï¼ˆæ›´ä¸¥æ ¼ï¼‰
            "error_rate_threshold": 0.1,  # é”™è¯¯ç‡é˜ˆå€¼
            "switch_cooldown_seconds": 30,  # åˆ‡æ¢å†·å´æ—¶é—´ï¼ˆç¼©çŸ­ï¼‰
            "memory_threshold_mb": 300,  # å†…å­˜ä½¿ç”¨é˜ˆå€¼ï¼ˆé™ä½ï¼‰
            "max_metrics": 500,  # æœ€å¤§æŒ‡æ ‡æ•°é‡ï¼ˆå‡å°‘ï¼‰
            "metric_retention_hours": 12  # æŒ‡æ ‡ä¿ç•™æ—¶é—´ï¼ˆç¼©çŸ­ï¼‰
        }
        
        # å†…å­˜ä¼˜åŒ–
        self.enable_gc_optimization = enable_gc_optimization
        self._last_gc_time = time.time()
        self._gc_interval = 300  # 5åˆ†é’Ÿ
        self._last_cleanup = time.time()
        self._cleanup_interval = 3600  # 1å°æ—¶æ¸…ç†ä¸€æ¬¡
        
        # ç¼“å­˜
        self._summary_cache = None
        self._cache_timestamp = None
        self._cache_ttl = 5  # ç¼“å­˜5ç§’
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._stats = {
            "total_metrics_created": 0,
            "total_metrics_cleaned": 0,
            "memory_cleanups": 0,
            "cache_hits": 0,
            "cache_misses": 0
        }
        
        # å¯åŠ¨æ¸…ç†ä»»åŠ¡
        self._cleanup_task = None
        self._start_cleanup_task()
    
    def _start_cleanup_task(self):
        """å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡"""
        try:
            async def cleanup_loop():
                while True:
                    try:
                        await asyncio.sleep(self._cleanup_interval)
                        await self._cleanup_expired_metrics()
                        self._check_memory_pressure()
                    except Exception as e:
                        logger.warning(f"æ€§èƒ½ç›‘æ§æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰äº‹ä»¶å¾ªç¯
            try:
                loop = asyncio.get_running_loop()
                self._cleanup_task = asyncio.create_task(cleanup_loop())
                logger.info("âœ… æ€§èƒ½ç›‘æ§æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨")
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œç¨åå¯åŠ¨
                logger.debug("â³ ç­‰å¾…äº‹ä»¶å¾ªç¯å¯åŠ¨åå†å¯åŠ¨æ€§èƒ½ç›‘æ§æ¸…ç†ä»»åŠ¡")
        except Exception as e:
            logger.warning(f"å¯åŠ¨æ€§èƒ½ç›‘æ§æ¸…ç†ä»»åŠ¡å¤±è´¥: {e}")
    
    async def _cleanup_expired_metrics(self):
        """æ¸…ç†è¿‡æœŸçš„æ€§èƒ½æŒ‡æ ‡"""
        try:
            expired_keys = []
            retention_hours = self.thresholds["metric_retention_hours"]
            
            with self._metrics_lock:
                for key, metric in list(self.metrics.items()):
                    if metric.is_expired(retention_hours):
                        expired_keys.append(key)
                
                # åˆ é™¤è¿‡æœŸæŒ‡æ ‡
                for key in expired_keys:
                    del self.metrics[key]
                
                self._stats["total_metrics_cleaned"] += len(expired_keys)
            
            if expired_keys:
                logger.info(f"ğŸ§¹ æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸæ€§èƒ½æŒ‡æ ‡")
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æŒ‡æ ‡æ•°é‡
            await self._enforce_max_metrics()
            
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡æœŸæŒ‡æ ‡å¤±è´¥: {e}")
    
    async def _enforce_max_metrics(self):
        """å¼ºåˆ¶æ‰§è¡Œæœ€å¤§æŒ‡æ ‡æ•°é‡é™åˆ¶"""
        try:
            max_metrics = self.thresholds["max_metrics"]
            
            with self._metrics_lock:
                if len(self.metrics) > max_metrics:
                    # æŒ‰æœ€åè°ƒç”¨æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„æŒ‡æ ‡
                    metrics_by_time = sorted(
                        self.metrics.items(),
                        key=lambda x: x[1].last_call or x[1].created_at
                    )
                    
                    excess_count = len(self.metrics) - max_metrics
                    for i in range(excess_count):
                        key = metrics_by_time[i][0]
                        del self.metrics[key]
                    
                    self._stats["total_metrics_cleaned"] += excess_count
                    logger.info(f"ğŸ§¹ å¼ºåˆ¶æ¸…ç†äº† {excess_count} ä¸ªæœ€æ—§çš„æ€§èƒ½æŒ‡æ ‡")
                    
        except Exception as e:
            logger.error(f"å¼ºåˆ¶æ¸…ç†æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _check_memory_pressure(self):
        """æ£€æŸ¥å†…å­˜å‹åŠ›å¹¶æ‰§è¡Œæ¸…ç†"""
        try:
            current_memory = self._get_memory_usage()
            memory_threshold = self.thresholds["memory_threshold_mb"]
            
            if current_memory > memory_threshold:
                logger.warning(f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {current_memory:.1f}MB > {memory_threshold}MB")
                
                # æ¸…ç†ç¼“å­˜
                self._clear_cache()
                
                # å¼ºåˆ¶åƒåœ¾å›æ”¶
                if self.enable_gc_optimization:
                    gc.collect()
                    self._stats["memory_cleanups"] += 1
                
                # å¦‚æœå†…å­˜ä»ç„¶è¿‡é«˜ï¼Œæ¸…ç†æ›´å¤šæŒ‡æ ‡
                with self._metrics_lock:
                    if len(self.metrics) > 100:
                        # ä¿ç•™æœ€è¿‘çš„100ä¸ªæŒ‡æ ‡
                        metrics_by_time = sorted(
                            self.metrics.items(),
                            key=lambda x: x[1].last_call or x[1].created_at,
                            reverse=True
                        )
                        
                        new_metrics = dict(metrics_by_time[:100])
                        cleaned_count = len(self.metrics) - len(new_metrics)
                        self.metrics = new_metrics
                        self._stats["total_metrics_cleaned"] += cleaned_count
                        
                        logger.warning(f"âš ï¸ å†…å­˜å‹åŠ›æ¸…ç†äº† {cleaned_count} ä¸ªæ€§èƒ½æŒ‡æ ‡")
                        
        except Exception as e:
            logger.error(f"æ£€æŸ¥å†…å­˜å‹åŠ›å¤±è´¥: {e}")
    
    def _clear_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        with self._lock:
            self._summary_cache = None
            self._cache_timestamp = None
    
    def _get_or_create_metrics(self, key: str) -> MetricData:
        """è·å–æˆ–åˆ›å»ºæŒ‡æ ‡æ•°æ®"""
        with self._metrics_lock:
            if key not in self.metrics:
                self.metrics[key] = MetricData()
                self._stats["total_metrics_created"] += 1
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
                if len(self.metrics) > self.thresholds["max_metrics"] * 1.1:
                    asyncio.create_task(self._enforce_max_metrics())
                    
            return self.metrics[key]
    
    def record_api_call(
        self,
        provider: str,
        function_type: str,
        duration: float,
        success: bool,
        error: Optional[Exception] = None,
        metadata: Optional[Dict] = None
    ):
        """è®°å½•APIè°ƒç”¨ - çº¿ç¨‹å®‰å…¨"""
        try:
            key = f"{provider}:{function_type}"
            
            with self._lock:
                metrics = self._get_or_create_metrics(key)
                
                # æ›´æ–°è®¡æ•°
                metrics.total_calls += 1
                if success:
                    metrics.successful_calls += 1
                else:
                    metrics.failed_calls += 1
                    if error:
                        error_type = type(error).__name__
                        if error_type not in metrics.error_types:
                            metrics.error_types[error_type] = 0
                        metrics.error_types[error_type] += 1
                
                # æ›´æ–°æ—¶é•¿ç»Ÿè®¡
                metrics.total_duration += duration
                metrics.min_duration = min(metrics.min_duration, duration)
                metrics.max_duration = max(metrics.max_duration, duration)
                metrics.avg_duration = metrics.total_duration / metrics.total_calls
                metrics.recent_durations.append(duration)
                
                # æ›´æ–°æœ€åè°ƒç”¨æ—¶é—´
                metrics.last_call = datetime.now()
                
                # æ¸…é™¤ç¼“å­˜
                self._clear_cache()
            
            # è®°å½•æ…¢å“åº”ï¼ˆåœ¨é”å¤–æ‰§è¡Œï¼‰
            if duration > self.thresholds["slow_response_ms"] / 1000:
                logger.warning(
                    f"æ…¢å“åº”æ£€æµ‹: {provider} {function_type} è€—æ—¶ {duration:.2f}ç§’"
                )
            
            # å®šæœŸåƒåœ¾å›æ”¶å’Œæ¸…ç†
            self._check_gc()
            
        except Exception as e:
            logger.error(f"è®°å½•APIè°ƒç”¨å¤±è´¥: {e}", exc_info=True)
    
    def record_provider_switch(
        self,
        from_provider: str,
        to_provider: str,
        reason: str,
        function_type: str
    ):
        """è®°å½•æä¾›å•†åˆ‡æ¢ - çº¿ç¨‹å®‰å…¨"""
        try:
            with self._lock:
                switch_event = {
                    "timestamp": datetime.now(),
                    "from": from_provider,
                    "to": to_provider,
                    "reason": reason,
                    "function_type": function_type
                }
                
                self.switch_history.append(switch_event)
                self.current_provider = to_provider
                self.last_switch_time = datetime.now()
                self.switch_count += 1
                
                # æ¸…é™¤ç¼“å­˜
                self._clear_cache()
            
            logger.info(
                f"æä¾›å•†åˆ‡æ¢: {from_provider} -> {to_provider} "
                f"(åŸå› : {reason}, åŠŸèƒ½: {function_type})"
            )
            
        except Exception as e:
            logger.error(f"è®°å½•æä¾›å•†åˆ‡æ¢å¤±è´¥: {e}", exc_info=True)
    
    @lru_cache(maxsize=32)
    def _calculate_success_rate(self, successful: int, total: int) -> float:
        """è®¡ç®—æˆåŠŸç‡ - å¸¦ç¼“å­˜"""
        return successful / total if total > 0 else 0.0
    
    def get_provider_stats(self, provider: str) -> Dict[str, Any]:
        """è·å–ç‰¹å®šæä¾›å•†çš„ç»Ÿè®¡ä¿¡æ¯ - ä¼˜åŒ–ç‰ˆæœ¬"""
        stats = {
            "provider": provider,
            "functions": {}
        }
        
        with self._lock:
            # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æé«˜æ•ˆç‡
            provider_metrics = [
                (key, metrics) 
                for key, metrics in self.metrics.items() 
                if key.startswith(f"{provider}:")
            ]
        
        for key, metrics in provider_metrics:
            function_type = key.split(":", 1)[1]
            
            # è®¡ç®—æˆåŠŸç‡
            success_rate = self._calculate_success_rate(
                metrics.successful_calls, 
                metrics.total_calls
            )
            
            # è®¡ç®—æœ€è¿‘çš„å¹³å‡å“åº”æ—¶é—´
            recent_durations = list(metrics.recent_durations)
            recent_avg = (
                sum(recent_durations) / len(recent_durations)
                if recent_durations else 0
            )
            
            stats["functions"][function_type] = {
                "total_calls": metrics.total_calls,
                "success_rate": success_rate,
                "avg_duration": metrics.avg_duration,
                "recent_avg_duration": recent_avg,
                "min_duration": metrics.min_duration if metrics.min_duration != float('inf') else 0,
                "max_duration": metrics.max_duration,
                "error_types": dict(metrics.error_types),
                "last_call": metrics.last_call.isoformat() if metrics.last_call else None
            }
        
        return stats
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦ - å¸¦ç¼“å­˜"""
        # æ£€æŸ¥ç¼“å­˜
        if self._summary_cache and self._cache_timestamp:
            if time.time() - self._cache_timestamp < self._cache_ttl:
                self._stats["cache_hits"] += 1
                return self._summary_cache
        
        self._stats["cache_misses"] += 1
        
        with self._lock:
            summary = {
                "timestamp": datetime.now().isoformat(),
                "current_provider": self.current_provider,
                "switch_count": self.switch_count,
                "last_switch": self.last_switch_time.isoformat() if self.last_switch_time else None,
                "providers": {},
                "memory_usage_mb": self._get_memory_usage(),
                "metrics_count": len(self.metrics),
                "stats": dict(self._stats)
            }
            
            # è·å–æ‰€æœ‰æä¾›å•†
            providers = {key.split(":", 1)[0] for key in self.metrics.keys()}
            
            # è·å–æ¯ä¸ªæä¾›å•†çš„ç»Ÿè®¡
            for provider in providers:
                summary["providers"][provider] = self.get_provider_stats(provider)
            
            # æ·»åŠ åˆ‡æ¢å†å²æ‘˜è¦
            if self.switch_history:
                recent_switches = list(self.switch_history)[-10:]  # æœ€è¿‘10æ¬¡åˆ‡æ¢
                summary["recent_switches"] = [
                    {
                        "timestamp": switch["timestamp"].isoformat(),
                        "from": switch["from"],
                        "to": switch["to"],
                        "reason": switch["reason"],
                        "function_type": switch["function_type"]
                    }
                    for switch in recent_switches
                ]
            
            # æ›´æ–°ç¼“å­˜
            self._summary_cache = summary
            self._cache_timestamp = time.time()
        
        return summary
    
    def should_switch_provider(
        self,
        current_provider: str,
        function_type: str
    ) -> Optional[str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ‡æ¢æä¾›å•† - ä¼˜åŒ–ç‰ˆæœ¬"""
        # æ£€æŸ¥å†·å´æ—¶é—´
        if self.last_switch_time:
            cooldown = timedelta(seconds=self.thresholds["switch_cooldown_seconds"])
            if datetime.now() - self.last_switch_time < cooldown:
                return None
        
        key = f"{current_provider}:{function_type}"
        
        with self._lock:
            metrics = self.metrics.get(key)
        
        if not metrics or metrics.total_calls < 10:
            return None  # æ•°æ®ä¸è¶³
        
        # æ£€æŸ¥é”™è¯¯ç‡
        error_rate = self._calculate_success_rate(
            metrics.failed_calls, 
            metrics.total_calls
        )
        if error_rate > self.thresholds["error_rate_threshold"]:
            logger.warning(
                f"{current_provider} {function_type} é”™è¯¯ç‡è¿‡é«˜: {error_rate:.2%}"
            )
            return "high_error_rate"
        
        # æ£€æŸ¥å“åº”æ—¶é—´
        recent_durations = list(metrics.recent_durations)
        if recent_durations:
            recent_avg = sum(recent_durations) / len(recent_durations)
            if recent_avg > self.thresholds["slow_response_ms"] / 1000:
                logger.warning(
                    f"{current_provider} {function_type} å“åº”è¿‡æ…¢: {recent_avg:.2f}s"
                )
                return "slow_response"
        
        return None
    
    def export_metrics(self, filepath: str):
        """å¯¼å‡ºæ€§èƒ½æŒ‡æ ‡åˆ°æ–‡ä»¶ - å¼‚æ­¥ç‰ˆæœ¬"""
        try:
            summary = self.get_performance_summary()
            
            # ä½¿ç”¨å¼‚æ­¥å†™å…¥
            async def _async_write():
                async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
                    await f.write(json.dumps(summary, indent=2, ensure_ascii=False))
            
            # å¦‚æœåœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­ï¼Œç›´æ¥æ‰§è¡Œ
            try:
                loop = asyncio.get_running_loop()
                asyncio.create_task(_async_write())
            except RuntimeError:
                # åŒæ­¥ç¯å¢ƒï¼Œä½¿ç”¨æ™®é€šå†™å…¥
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"æ€§èƒ½æŒ‡æ ‡å·²å¯¼å‡ºåˆ°: {filepath}")
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºæ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}", exc_info=True)
    
    def reset_metrics(self):
        """é‡ç½®æ‰€æœ‰æŒ‡æ ‡ - çº¿ç¨‹å®‰å…¨"""
        with self._lock:
            self.metrics.clear()
            self.switch_history.clear()
            self.switch_count = 0
            self.last_switch_time = None
            self._clear_cache()
            
            # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
            self._stats = {
                "total_metrics_created": 0,
                "total_metrics_cleaned": 0,
                "memory_cleanups": 0,
                "cache_hits": 0,
                "cache_misses": 0
            }
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            if self.enable_gc_optimization:
                gc.collect()
            
        logger.info("æ€§èƒ½æŒ‡æ ‡å·²é‡ç½®")
    
    def _check_gc(self):
        """æ£€æŸ¥å¹¶æ‰§è¡Œåƒåœ¾å›æ”¶"""
        if not self.enable_gc_optimization:
            return
        
        current_time = time.time()
        if current_time - self._last_gc_time > self._gc_interval:
            self._last_gc_time = current_time
            gc.collect(0)  # åªæ”¶é›†ç¬¬0ä»£
    
    def _get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        try:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024
        except ImportError:
            # å¦‚æœæ²¡æœ‰psutilï¼Œè¿”å›ä¼°ç®—å€¼
            import sys
            return sys.getsizeof(self.metrics) / 1024 / 1024
    
    @contextmanager
    def batch_record(self):
        """æ‰¹é‡è®°å½•ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        batch_records = []
        
        def batch_record_api_call(**kwargs):
            batch_records.append(kwargs)
        
        # ä¸´æ—¶æ›¿æ¢è®°å½•æ–¹æ³•
        original_record = self.record_api_call
        self.record_api_call = batch_record_api_call
        
        try:
            yield
        finally:
            # æ¢å¤åŸæ–¹æ³•
            self.record_api_call = original_record
            
            # æ‰¹é‡å¤„ç†è®°å½•
            with self._lock:
                for record in batch_records:
                    self.record_api_call(**record)
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # å–æ¶ˆæ¸…ç†ä»»åŠ¡
            if self._cleanup_task and not self._cleanup_task.done():
                self._cleanup_task.cancel()
                try:
                    await self._cleanup_task
                except asyncio.CancelledError:
                    pass
            
            # æ¸…ç†æ‰€æœ‰æŒ‡æ ‡
            self.reset_metrics()
            
            logger.info("âœ… PerformanceMonitorèµ„æºå·²æ¸…ç†")
            
        except Exception as e:
            logger.warning(f"âš ï¸ PerformanceMonitoræ¸…ç†æ—¶å‡ºç°è­¦å‘Š: {e}")

    def record_realtime_voice_call(
        self,
        provider: str,
        duration: float,
        success: bool,
        latency: Optional[float] = None,
        audio_quality: Optional[str] = None,
        error: Optional[Exception] = None
    ):
        """è®°å½•å®æ—¶è¯­éŸ³è°ƒç”¨çš„ä¸“ç”¨æ–¹æ³•"""
        try:
            # ä½¿ç”¨ç‰¹æ®Šçš„keyæ ‡è¯†å®æ—¶è¯­éŸ³è°ƒç”¨
            key = f"{provider}:realtime_voice"
            
            with self._lock:
                metrics = self._get_or_create_metrics(key)
                
                # æ›´æ–°åŸºç¡€ç»Ÿè®¡
                metrics.total_calls += 1
                if success:
                    metrics.successful_calls += 1
                else:
                    metrics.failed_calls += 1
                    if error:
                        error_type = type(error).__name__
                        if error_type not in metrics.error_types:
                            metrics.error_types[error_type] = 0
                        metrics.error_types[error_type] += 1
                
                # æ›´æ–°æ—¶é•¿ç»Ÿè®¡
                metrics.total_duration += duration
                metrics.min_duration = min(metrics.min_duration, duration)
                metrics.max_duration = max(metrics.max_duration, duration)
                metrics.avg_duration = metrics.total_duration / metrics.total_calls
                metrics.recent_durations.append(duration)
                metrics.last_call = datetime.now()
                
                # æ¸…é™¤ç¼“å­˜
                self._clear_cache()
            
            # å®æ—¶è¯­éŸ³ç‰¹æ®Šæ£€æŸ¥
            realtime_threshold = self.thresholds["realtime_voice_ms"] / 1000
            if duration > realtime_threshold:
                logger.warning(
                    f"å®æ—¶è¯­éŸ³å“åº”è¿‡æ…¢: {provider} è€—æ—¶ {duration:.2f}ç§’ > {realtime_threshold}ç§’",
                    extra={
                        "provider": provider,
                        "duration": duration,
                        "threshold": realtime_threshold,
                        "latency": latency,
                        "audio_quality": audio_quality
                    }
                )
            
            # è®°å½•åˆ°æ™®é€šAPIè°ƒç”¨
            self.record_api_call(provider, "realtime_voice", duration, success, error, {
                "latency": latency,
                "audio_quality": audio_quality,
                "is_realtime": True
            })
            
        except Exception as e:
            logger.error(f"è®°å½•å®æ—¶è¯­éŸ³è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
    
    def get_realtime_voice_performance(self) -> Dict[str, Any]:
        """è·å–å®æ—¶è¯­éŸ³æ€§èƒ½ç»Ÿè®¡"""
        try:
            performance = {
                "providers": {},
                "overall": {
                    "total_calls": 0,
                    "avg_latency": 0,
                    "success_rate": 0,
                    "slow_calls": 0
                }
            }
            
            realtime_threshold = self.thresholds["realtime_voice_ms"] / 1000
            total_calls = 0
            total_duration = 0
            total_success = 0
            slow_calls = 0
            
            with self._lock:
                for key, metrics in self.metrics.items():
                    if ":realtime_voice" in key:
                        provider = key.split(":")[0]
                        
                        # è®¡ç®—æ…¢è°ƒç”¨æ•°é‡
                        recent_slow = sum(
                            1 for d in metrics.recent_durations 
                            if d > realtime_threshold
                        )
                        
                        performance["providers"][provider] = {
                            "total_calls": metrics.total_calls,
                            "success_rate": metrics.successful_calls / metrics.total_calls if metrics.total_calls > 0 else 0,
                            "avg_duration": metrics.avg_duration,
                            "min_duration": metrics.min_duration if metrics.min_duration != float('inf') else 0,
                            "max_duration": metrics.max_duration,
                            "slow_calls": recent_slow,
                            "error_types": dict(metrics.error_types),
                            "last_call": metrics.last_call.isoformat() if metrics.last_call else None
                        }
                        
                        # ç´¯è®¡æ€»ä½“ç»Ÿè®¡
                        total_calls += metrics.total_calls
                        total_duration += metrics.total_duration
                        total_success += metrics.successful_calls
                        slow_calls += recent_slow
            
            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            if total_calls > 0:
                performance["overall"] = {
                    "total_calls": total_calls,
                    "avg_latency": total_duration / total_calls,
                    "success_rate": total_success / total_calls,
                    "slow_calls": slow_calls,
                    "slow_rate": slow_calls / total_calls
                }
            
            return performance
            
        except Exception as e:
            logger.error(f"è·å–å®æ—¶è¯­éŸ³æ€§èƒ½å¤±è´¥: {e}")
            return {"error": str(e)}


class PerformanceContext:
    """æ€§èƒ½ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(
        self,
        monitor: PerformanceMonitor,
        provider: str,
        function_type: str,
        metadata: Optional[Dict] = None
    ):
        self.monitor = monitor
        self.provider = provider
        self.function_type = function_type
        self.metadata = metadata or {}
        self.start_time = None
        self.success = True
        self.error = None
    
    async def __aenter__(self):
        self.start_time = time.perf_counter()  # ä½¿ç”¨æ›´ç²¾ç¡®çš„è®¡æ—¶å™¨
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        duration = time.perf_counter() - self.start_time
        
        if exc_type is not None:
            self.success = False
            self.error = exc_val
            
        # è®°å½•APIè°ƒç”¨
        self.monitor.record_api_call(
            provider=self.provider,
            function_type=self.function_type,
            duration=duration,
            success=self.success,
            error=self.error,
            metadata=self.metadata
        )
        
# å…¨å±€æ€§èƒ½ç›‘æ§å™¨å®ä¾‹
_performance_monitor: Optional[PerformanceMonitor] = None
_monitor_lock = threading.Lock()

def get_performance_monitor() -> PerformanceMonitor:
    """è·å–å…¨å±€æ€§èƒ½ç›‘æ§å™¨å®ä¾‹ - çº¿ç¨‹å®‰å…¨"""
    global _performance_monitor
    
    if _performance_monitor is None:
        with _monitor_lock:
            if _performance_monitor is None:
                _performance_monitor = PerformanceMonitor()
    
    return _performance_monitor


# ä¸ºäº†PrometheusæŒ‡æ ‡å¯¼å‡ºï¼Œæ·»åŠ é¢å¤–çš„æŒ‡æ ‡è·Ÿè¸ª
class PrometheusMetrics:
    """PrometheusæŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self._api_latencies = defaultdict(deque)  # APIå»¶è¿Ÿ
        self._error_counts = defaultdict(int)     # é”™è¯¯è®¡æ•°
        self._request_counts = defaultdict(int)   # è¯·æ±‚è®¡æ•°
        self._response_times = defaultdict(deque) # å“åº”æ—¶é—´
        self._provider_switches = 0               # åˆ‡æ¢æ¬¡æ•°
        self.active_requests = 0                  # æ´»è·ƒè¯·æ±‚æ•°
        self._lock = threading.Lock()
        
        # æœ€å¤§å†å²è®°å½•
        self.max_history = 1000
    
    def record_api_latency(self, endpoint: str, latency_ms: float):
        """è®°å½•APIå»¶è¿Ÿ"""
        with self._lock:
            if len(self._api_latencies[endpoint]) >= self.max_history:
                self._api_latencies[endpoint].popleft()
            self._api_latencies[endpoint].append(latency_ms)
    
    def record_error(self, endpoint: str, error: str):
        """è®°å½•é”™è¯¯"""
        with self._lock:
            self._error_counts[endpoint] += 1
    
    def increment_switch_count(self):
        """å¢åŠ åˆ‡æ¢è®¡æ•°"""
        with self._lock:
            self._provider_switches += 1


# æ‰©å±•PerformanceMonitorä»¥æ”¯æŒPrometheus
def _extend_performance_monitor():
    """æ‰©å±•æ€§èƒ½ç›‘æ§å™¨ä»¥æ”¯æŒPrometheusæŒ‡æ ‡"""
    monitor = get_performance_monitor()
    
    # æ·»åŠ PrometheusæŒ‡æ ‡å±æ€§
    if not hasattr(monitor, '_prometheus_metrics'):
        monitor._prometheus_metrics = PrometheusMetrics()
        
        # æ·»åŠ åŸå§‹çš„record_api_latencyæ–¹æ³•
        original_record = monitor.record_api_call
        
        def enhanced_record_api_call(provider, function_type, duration, success, error=None, metadata=None):
            # è°ƒç”¨åŸæ–¹æ³•
            original_record(provider, function_type, duration, success, error, metadata)
            
            # è®°å½•åˆ°PrometheusæŒ‡æ ‡
            endpoint = f"{provider}.{function_type}"
            monitor._prometheus_metrics.record_api_latency(endpoint, duration * 1000)
            monitor._prometheus_metrics._request_counts[endpoint] += 1
            
            if not success:
                monitor._prometheus_metrics.record_error(endpoint, str(error) if error else "unknown")
        
        monitor.record_api_call = enhanced_record_api_call
        
        # æ·»åŠ record_api_latencyæ–¹æ³•ï¼ˆå‘åå…¼å®¹ï¼‰
        def record_api_latency(endpoint: str, latency_ms: float):
            monitor._prometheus_metrics.record_api_latency(endpoint, latency_ms)
        
        monitor.record_api_latency = record_api_latency
        
        # æ·»åŠ record_erroræ–¹æ³•
        def record_error(endpoint: str, error: str):
            monitor._prometheus_metrics.record_error(endpoint, error)
        
        monitor.record_error = record_error
        
        # ä¿®æ”¹åˆ‡æ¢è®°å½•ä»¥å¢åŠ è®¡æ•°
        original_switch = monitor.record_provider_switch
        
        def enhanced_switch(from_provider, to_provider, reason, function_type):
            original_switch(from_provider, to_provider, reason, function_type)
            monitor._prometheus_metrics.increment_switch_count()
        
        monitor.record_provider_switch = enhanced_switch
        
        # æ·»åŠ Prometheuså¯¼å‡ºæ–¹æ³•
        def export_prometheus_metrics() -> str:
            """å¯¼å‡ºPrometheusæ ¼å¼çš„æŒ‡æ ‡"""
            import psutil
            
            lines = []
            metrics = monitor._prometheus_metrics
            
            # å¯¼å‡ºAPIå»¶è¿ŸæŒ‡æ ‡
            lines.append("# HELP vita_api_latency_milliseconds APIè°ƒç”¨å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰")
            lines.append("# TYPE vita_api_latency_milliseconds summary")
            
            with metrics._lock:
                for endpoint, latencies in metrics._api_latencies.items():
                    if latencies:
                        recent = list(latencies)
                        avg_latency = sum(recent) / len(recent)
                        lines.append(f'vita_api_latency_milliseconds{{endpoint="{endpoint}",quantile="0.5"}} {avg_latency:.2f}')
                        if recent:
                            sorted_latencies = sorted(recent)
                            p95_idx = int(len(sorted_latencies) * 0.95)
                            p95 = sorted_latencies[p95_idx] if p95_idx < len(sorted_latencies) else sorted_latencies[-1]
                            lines.append(f'vita_api_latency_milliseconds{{endpoint="{endpoint}",quantile="0.95"}} {p95:.2f}')
            
            # å¯¼å‡ºé”™è¯¯ç‡æŒ‡æ ‡
            lines.append("\n# HELP vita_error_rate é”™è¯¯ç‡")
            lines.append("# TYPE vita_error_rate gauge")
            error_count = sum(metrics._error_counts.values())
            total_requests = sum(metrics._request_counts.values())
            error_rate = error_count / total_requests if total_requests > 0 else 0
            lines.append(f"vita_error_rate {error_rate:.4f}")
            
            # å¯¼å‡ºåˆ‡æ¢æ¬¡æ•°æŒ‡æ ‡
            lines.append("\n# HELP vita_provider_switch_count æä¾›å•†åˆ‡æ¢æ¬¡æ•°")
            lines.append("# TYPE vita_provider_switch_count counter")
            with metrics._lock:
                lines.append(f"vita_provider_switch_count {metrics._provider_switches}")
            
            # å¯¼å‡ºå“åº”æ—¶é—´æŒ‡æ ‡
            lines.append("\n# HELP vita_response_time_seconds å“åº”æ—¶é—´ï¼ˆç§’ï¼‰")
            lines.append("# TYPE vita_response_time_seconds histogram")
            
            with monitor._lock:
                for key, metric_data in monitor.metrics.items():
                    provider, function = key.split(":", 1)
                    if metric_data.recent_durations:
                        for duration in list(metric_data.recent_durations):
                            lines.append(f'__REMOVED_API_KEY__{{provider="{provider}",function="{function}",le="{duration:.2f}"}} 1')
            
            # å¯¼å‡ºæ´»è·ƒè¯·æ±‚æ•°
            lines.append("\n# HELP vita_active_requests æ´»è·ƒè¯·æ±‚æ•°")
            lines.append("# TYPE vita_active_requests gauge")
            lines.append(f"vita_active_requests {metrics.active_requests}")
            
            # å¯¼å‡ºå†…å­˜ä½¿ç”¨
            lines.append("\n# HELP vita_memory_usage_mb å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰")
            lines.append("# TYPE vita_memory_usage_mb gauge")
            memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
            lines.append(f"vita_memory_usage_mb {memory_mb:.2f}")
            
            # å¯¼å‡ºCPUä½¿ç”¨ç‡
            lines.append("\n# HELP vita_cpu_usage_percent CPUä½¿ç”¨ç‡")
            lines.append("# TYPE vita_cpu_usage_percent gauge")
            cpu_percent = psutil.Process().cpu_percent(interval=0.1)
            lines.append(f"vita_cpu_usage_percent {cpu_percent:.2f}")
            
            return "\n".join(lines) + "\n"
        
        monitor.export_prometheus_metrics = export_prometheus_metrics
    
    return monitor


# åˆå§‹åŒ–æ‰©å±•
_extend_performance_monitor() 