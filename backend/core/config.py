"""
VITAé…ç½®ç®¡ç†æ¨¡å—
ç®¡ç†æ‰€æœ‰ç¯å¢ƒå˜é‡å’Œæ¨¡å‹é…ç½® - çº¯æœ¬åœ°è¯­éŸ³æœåŠ¡ç‰ˆæœ¬
"""

import os
import logging
from typing import Dict, Any, Optional
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VITAConfig:
    """VITAé¡¹ç›®é…ç½®ç±» - çº¯æœ¬åœ°è¯­éŸ³æœåŠ¡ç‰ˆæœ¬"""
    
    # è±†åŒ…å®æ—¶è¯­éŸ³å¤§æ¨¡å‹å¸¸é‡ - æ›´æ–°ä¸ºæœ€æ–°æ¨¡å‹
    REALTIME_VOICE_MODEL = "Doubao-Seed-1.6-flash"  # æé€Ÿå“åº”ï¼ŒTPOTä»…éœ€10ms
    
    # è±†åŒ…ä¸“ä¸šè¯­éŸ³å¤§æ¨¡å‹å¸¸é‡ - åŸºäºå›¾ç‰‡ä¸­çš„ä¸“ä¸šè¯­éŸ³æ¨¡å‹
    REALTIME_VOICE_MODEL = "Doubao-Seed-1.6-flash"      # å®æ—¶å¯¹è¯ï¼šæé€Ÿå“åº”ï¼ŒTPOTä»…éœ€10ms
    VOICE_RECOGNITION_MODEL = "Doubao-æµå¼è¯­éŸ³è¯†åˆ«"       # ä¸“ä¸šæµå¼è¯­éŸ³è¯†åˆ«
    VOICE_SYNTHESIS_MODEL = "Doubao-è¯­éŸ³åˆæˆ"           # ä¸“ä¸šè¯­éŸ³åˆæˆ
    VOICE_FILE_MODEL = "Doubao-å½•éŸ³æ–‡ä»¶è¯†åˆ«"            # å½•éŸ³æ–‡ä»¶è¯†åˆ«
    VOICE_CLONING_MODEL = "Doubao-å£°éŸ³å¤åˆ»"             # å£°éŸ³å¤åˆ»ï¼ˆé«˜çº§åŠŸèƒ½ï¼‰
    
    # è±†åŒ…MVPæœ€ä¼˜æ¶æ„é…ç½® - åŸºäºå›¾ç‰‡ä¸­æ‰€æœ‰å¯ç”¨æ¨¡å‹çš„æœ€ä¼˜é€‰æ‹©
    MODEL_CONFIG = {
        "doubao": {
            # ğŸš€ å®æ—¶äº¤äº’ï¼šæé€Ÿå“åº”æ¨¡å‹ (TPOTä»…éœ€10ms)
            "chat": "Doubao-Seed-1.6-flash",                    # å®æ—¶èŠå¤© - 10msæé€Ÿå“åº”
            "realtime_voice": "Doubao-Seed-1.6-flash",          # å®æ—¶è¯­éŸ³äº¤äº’ - æé€Ÿå“åº”æ ¸å¿ƒ
            
            # ğŸ§  æ·±åº¦åˆ†æï¼šå¼ºæ€è€ƒæ¨¡å‹ (Coding/Mathèƒ½åŠ›å¤§å¹…æå‡)
            "interview": "Doubao-Seed-1.6-thinking",            # é¢è¯•å¯¹è¯ - æ·±åº¦æ€è€ƒæ¨ç†
            "analysis": "Doubao-Seed-1.6-thinking",             # æ·±åº¦åˆ†æ - å¼ºåŒ–æ€è€ƒèƒ½åŠ›
            "code": "Doubao-Seed-1.6-thinking",                 # ä»£ç è¯„ä¼° - Codingè¡¨ç°æ›´å¼º
            "math": "Doubao-Seed-1.6-thinking",                 # æ•°å­¦æ¨ç† - Mathè¡¨ç°æ›´å¼º
            
            # ğŸ¤ ä¸“ä¸šè¯­éŸ³æ¨¡å‹ï¼šè±†åŒ…è¯­éŸ³ä¸“ç”¨æ¨¡å‹
            "voice_recognition": "Doubao-æµå¼è¯­éŸ³è¯†åˆ«",           # ä¸“ä¸šæµå¼è¯­éŸ³è¯†åˆ«
            "voice_synthesis": "Doubao-è¯­éŸ³åˆæˆ",               # ä¸“ä¸šè¯­éŸ³åˆæˆ
            "voice_file_recognition": "Doubao-å½•éŸ³æ–‡ä»¶è¯†åˆ«",       # å½•éŸ³æ–‡ä»¶è¯†åˆ«
            "voice_cloning": "Doubao-å£°éŸ³å¤åˆ»",                 # å£°éŸ³å¤åˆ»ï¼ˆé«˜çº§åŠŸèƒ½ï¼‰
            
            # ğŸ” å¤šæ¨¡æ€ç†è§£ï¼šè§†è§‰æ€è€ƒæ¨¡å‹
            "multimodal_interview": "Doubao-1.5-thinking-vision-pro",  # å¤šæ¨¡æ€é¢è¯• - è§†è§‰æ·±åº¦æ€è€ƒ
            "vision": "Doubao-1.5-vision-pro",                 # è§†è§‰é—®ç­” - å¤šæ¨¡æ€ç†è§£
            "multimodal": "Doubao-Seed-1.6",                   # é€šç”¨å¤šæ¨¡æ€å¤„ç†
            
            # ğŸ“„ é•¿æ–‡æœ¬å¤„ç†ï¼šè¶…é•¿ä¸Šä¸‹æ–‡æ¨¡å‹
            "long_context": "Doubao-pro-256k",                 # è¶…é•¿ä¸Šä¸‹æ–‡ - 256k token
            "document_analysis": "Doubao-pro-256k",            # æ–‡æ¡£åˆ†æ - é•¿æ–‡æœ¬ç†è§£
            
            # ğŸ”„ å¤‡ç”¨å’Œè½»é‡çº§æ¨¡å‹
            "fallback": "Doubao-lite-4k",                      # è½»é‡å¤‡ç”¨ - å¿«é€Ÿå“åº”
            "lite": "Doubao-lite-128k",                        # ä¸­ç­‰è½»é‡ - å¹³è¡¡æ€§èƒ½
            
            # ğŸµ æœ¬åœ°å¤‡ç”¨ï¼ˆä¿æŒåŸæœ‰æœ¬åœ°èƒ½åŠ›ï¼‰
            "speech_recognition_fallback": "local-whisper",     # æœ¬åœ°è¯­éŸ³è¯†åˆ«å¤‡ç”¨
            "speech_synthesis_fallback": "local-tts",          # æœ¬åœ°è¯­éŸ³åˆæˆå¤‡ç”¨
        },
        
        # Qwenç³»åˆ— - ä½œä¸ºäºŒçº§å¤‡ç”¨
        "qwen": {
            "chat": "qwen-plus",
            "analysis": "qwen-plus", 
            "interview": "qwen-plus",
            "code": "Qwen/Qwen2.5-Coder-32B-Instruct",
            "math": "Qwen/Qwen2.5-Math-72B-Instruct",
            "fallback": "qwen-turbo",
            "vision": "Qwen/Qwen2-VL-72B-Instruct",
            "long_context": "qwen-long",
            "turbo": "qwen-turbo",
            "audio": "Qwen/Qwen2-Audio-7B-Instruct",
            "speech_recognition": "local-whisper",
            "speech_synthesis": "local-tts"
        },
        
        # Llamaç³»åˆ— - ä½œä¸ºæœ€ç»ˆå¤‡ç”¨
        "llama": {
            "chat": "Llama-3.3-70B-Instruct",
            "analysis": "__REMOVED_API_KEY__",
            "interview": "Llama-3.3-70B-Instruct", 
            "code": "__REMOVED_API_KEY__",
            "math": "__REMOVED_API_KEY__",
            "fallback": "Llama-3.3-8B-Instruct",
            "speech_recognition": "local-whisper",
            "speech_synthesis": "local-tts"
        }
    }
    
    # ä¸‰æ¨¡å‹æ¶æ„é…ç½®å¼€å…³ - ç°åœ¨è±†åŒ…ä¼˜å…ˆ
    USE_DOUBAO_PRIMARY = True   # æ˜¯å¦å¯ç”¨è±†åŒ…ä½œä¸ºä¸»è¦æ–¹æ¡ˆï¼ˆæ–°å¢ï¼‰
    USE_QWEN_FALLBACK = True    # æ˜¯å¦å¯ç”¨Qwenä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
    USE_LLAMA_FALLBACK = True   # æ˜¯å¦å¯ç”¨Llamaä½œä¸ºæœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆ
    ENABLE_AUTO_SWITCH = True   # æ˜¯å¦å¯ç”¨è‡ªåŠ¨åˆ‡æ¢
    PREFER_DOUBAO = True        # ä¼˜å…ˆä½¿ç”¨è±†åŒ…ï¼ˆæ–°å¢ï¼‰
    PREFER_QWEN = False         # ä¸å†ä¼˜å…ˆä½¿ç”¨Qwen
    PREFER_LLAMA = False        # ä¸å†ä¼˜å…ˆä½¿ç”¨Llama
    
    # æœ¬åœ°Whisperé…ç½® - å¼ºåˆ¶å¯ç”¨æœ¬åœ°Whisper
    USE_LOCAL_WHISPER = True  # å¼ºåˆ¶å¯ç”¨æœ¬åœ°Whisper
    LOCAL_WHISPER_MODEL = os.getenv("LOCAL_WHISPER_MODEL", "medium")
    LOCAL_WHISPER_DEVICE = os.getenv("LOCAL_WHISPER_DEVICE", "auto")
    LOCAL_WHISPER_COMPUTE_TYPE = os.getenv("LOCAL_WHISPER_COMPUTE_TYPE", "float16")
    LOCAL_WHISPER_MODEL_DIR = os.getenv("LOCAL_WHISPER_MODEL_DIR", "whisper_download")
    DISABLE_WHISPER_ONLINE = os.getenv("DISABLE_WHISPER_ONLINE", "false").lower() == "true"
    
    # æœ¬åœ°TTSé…ç½® - ä¿ç•™ä½œä¸ºæœ€ç»ˆå¤‡ç”¨
    USE_LOCAL_TTS = True  # ä¿ç•™æœ¬åœ°TTSä½œä¸ºå¤‡ç”¨
    LOCAL_TTS_ENGINE = os.getenv("LOCAL_TTS_ENGINE", "edge-tts")  # edge-tts/pyttsx3
    
    # è±†åŒ…APIé…ç½®ï¼ˆä¸»è¦æ–¹æ¡ˆï¼‰
    DOUBAO_API_KEY = os.getenv("DOUBAO_API_KEY", "__REMOVED_API_KEY__")  # ç”¨æˆ·æä¾›çš„è±†åŒ…APIå¯†é’¥ï¼ˆUUIDæ ¼å¼ï¼‰
    DOUBAO_API_BASE_URL = os.getenv("DOUBAO_API_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
    DOUBAO_REALTIME_URL = os.getenv("DOUBAO_REALTIME_URL", "wss://openspeech.bytedance.com/api/v3/realtime/dialogue")  # æ›´æ–°ä¸ºæ­£ç¡®çš„WebSocket URL
    
    # Qwen APIé…ç½®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    QWEN_API_KEY = os.getenv("QWEN_API_KEY", "__REMOVED_API_KEY__")
    
    # Llama APIé…ç½®ï¼ˆæœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    LLAMA_API_KEY = os.getenv("LLAMA_API_KEY", "LLM|727268019715816|R9EX2i7cmHya1_7HAFiIAxxtAUk")
    LLAMA_API_BASE_URL = os.getenv("LLAMA_API_BASE_URL", "https://api.llama-api.com/v1")
    
    # è¯­éŸ³é…ç½® - è±†åŒ…ä¸“ä¸šè¯­éŸ³MVPæ–¹æ¡ˆ
    VOICE_CONFIG = {
        "primary_service": "doubao",              # ä¸»è¦è¯­éŸ³æœåŠ¡ï¼šè±†åŒ…ä¸“ä¸šè¯­éŸ³æ¨¡å‹
        "fallback_service": "local",              # å¤‡ç”¨è¯­éŸ³æœåŠ¡ï¼šæœ¬åœ°æœåŠ¡
        
        # è±†åŒ…ä¸“ä¸šè¯­éŸ³æ¨¡å‹é…ç½®
        "doubao_voice_models": {
            "realtime_recognition": "Doubao-æµå¼è¯­éŸ³è¯†åˆ«",    # å®æ—¶æµå¼è¯­éŸ³è¯†åˆ«
            "file_recognition": "Doubao-å½•éŸ³æ–‡ä»¶è¯†åˆ«",        # æ–‡ä»¶è¯­éŸ³è¯†åˆ«  
            "synthesis": "Doubao-è¯­éŸ³åˆæˆ",                 # ä¸“ä¸šè¯­éŸ³åˆæˆ
            "voice_cloning": "Doubao-å£°éŸ³å¤åˆ»",             # å£°éŸ³å¤åˆ»
            "realtime_conversation": "Doubao-Seed-1.6-flash" # å®æ—¶å¯¹è¯ï¼ˆ10msæé€Ÿï¼‰
        },
        
        # è¯­éŸ³è´¨é‡é…ç½®
        "default_voice": "professional_female",   # è±†åŒ…ä¸“ä¸šå¥³æ€§å£°éŸ³ï¼Œé€‚åˆé¢è¯•
        "fallback_voice": "nova",                # æœ¬åœ°å¤‡ç”¨å£°éŸ³
        "default_speed": 1.0,                    # æ­£å¸¸è¯­é€Ÿ
        "quality_mode": "high",                  # é«˜è´¨é‡æ¨¡å¼
        
        # æŠ€æœ¯å‚æ•°
        "max_audio_size_mb": 25,                 # æœ€å¤§éŸ³é¢‘æ–‡ä»¶å¤§å°
        "supported_formats": ["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"],
        "sample_rate": 16000,                    # é‡‡æ ·ç‡
        "chunk_duration_ms": 1000,              # åˆ†å—å¤„ç†æ—¶é•¿
        
        # æœ¬åœ°å¤‡ç”¨é…ç½®
        "tts_engine": "edge-tts",                # æœ¬åœ°TTSå¼•æ“ï¼ˆå¤‡ç”¨ï¼‰
        "whisper_model": "medium",               # æœ¬åœ°Whisperæ¨¡å‹ï¼ˆå¤‡ç”¨ï¼‰
        "use_realtime_voice": True,              # å¯ç”¨å®æ—¶è¯­éŸ³äº¤äº’
        
        # å®æ—¶è¯­éŸ³åŠŸèƒ½é…ç½®
        "realtime_features": {
            "stream_recognition": True,           # æµå¼è¯­éŸ³è¯†åˆ«
            "real_time_synthesis": True,         # å®æ—¶è¯­éŸ³åˆæˆ
            "voice_interruption": True,          # è¯­éŸ³æ‰“æ–­åŠŸèƒ½
            "echo_cancellation": True,           # å›å£°æ¶ˆé™¤
            "noise_reduction": True,             # å™ªéŸ³é™ä½
            "auto_gain_control": True            # è‡ªåŠ¨å¢ç›Šæ§åˆ¶
        },
        
        # é«˜çº§è¯­éŸ³åŠŸèƒ½
        "advanced_features": {
            "voice_cloning": True,               # å£°éŸ³å¤åˆ»åŠŸèƒ½
            "emotion_synthesis": True,           # æƒ…æ„Ÿè¯­éŸ³åˆæˆ
            "multi_speaker": True,               # å¤šè¯´è¯äººè¯†åˆ«
            "background_noise_handling": True   # èƒŒæ™¯å™ªéŸ³å¤„ç†
        }
    }
    
    # æœåŠ¡å™¨é…ç½®
    SERVER_CONFIG = {
        "host": "0.0.0.0",
        "backend_port": 8000,
        "vision_port": 8001,
        "frontend_port": 5173,
        "debug": True
    }
    
    # æ€§èƒ½é…ç½® - ä¼˜åŒ–å†…å­˜ä½¿ç”¨
    PERFORMANCE_CONFIG = {
        "cache_size": 50,              # å‡å°‘ç¼“å­˜å¤§å°ä»¥èŠ‚çœå†…å­˜
        "request_timeout": 30,         # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
        "max_concurrent_requests": 5,  # å‡å°‘æœ€å¤§å¹¶å‘è¯·æ±‚æ•°ä»¥èŠ‚çœå†…å­˜
        "rate_limit_per_minute": 60,   # æ¯åˆ†é’Ÿè¯·æ±‚é™åˆ¶
        "memory_limit_mb": 500,        # å†…å­˜ä½¿ç”¨é™åˆ¶(MB)
        "gc_threshold": 300,           # åƒåœ¾å›æ”¶é˜ˆå€¼(MB)
        "model_cache_size": 2,         # æœ€å¤šç¼“å­˜2ä¸ªæ¨¡å‹å®ä¾‹
        "connection_pool_size": 10,    # è¿æ¥æ± å¤§å°
        "max_retries": 3               # æœ€å¤§é‡è¯•æ¬¡æ•°
    }
    
    # Qwenç‰¹æœ‰åŠŸèƒ½é…ç½®
    QWEN_FEATURES = {
        "enable_vision": True,  # å¯ç”¨è§†è§‰ç†è§£
        "enable_long_context": True,  # å¯ç”¨é•¿æ–‡æœ¬å¤„ç†
        "max_context_length": 32000,  # Qwenæ”¯æŒçš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
        "enable_function_calling": True,  # å¯ç”¨å‡½æ•°è°ƒç”¨
        "enable_plugins": True,  # å¯ç”¨æ’ä»¶ç³»ç»Ÿ
        "supported_plugins": ["web_search", "calculator", "code_interpreter"]
    }
    
    @classmethod
    def _validate_key(cls, key: str) -> str:
        """éªŒè¯APIå¯†é’¥æ ¼å¼å¹¶è¿”å›ç±»å‹"""
        if not key or not isinstance(key, str):
            raise ValueError("æ— æ•ˆçš„APIå¯†é’¥æ ¼å¼")
        
        key = key.strip()
        
        # Qwenå¯†é’¥æ ¼å¼ï¼šsk-xxxï¼ˆéœ€è¦ä¼˜å…ˆæ£€æŸ¥ï¼Œé¿å…è¢«è±†åŒ…é€»è¾‘è¯¯è¯†åˆ«ï¼‰
        if key.startswith("sk-") and len(key) >= 30 and len(key) <= 60:
            logger.debug(f"âœ… æ£€æµ‹åˆ°æœ‰æ•ˆçš„Qwen APIå¯†é’¥")
            return 'qwen'
        
        # Llama APIå¯†é’¥æ ¼å¼ï¼šLLM|æ•°å­—|å­—ç¬¦ä¸²
        elif key.startswith("LLM|"):
            parts = key.split("|")
            if len(parts) >= 3 and parts[1].isdigit():
                logger.debug(f"âœ… æ£€æµ‹åˆ°æœ‰æ•ˆçš„Llama APIå¯†é’¥")
                return 'llama'
            else:
                raise ValueError("Llama APIå¯†é’¥æ ¼å¼ä¸æ­£ç¡®")
        
        # è±†åŒ…APIå¯†é’¥æ ¼å¼æ”¯æŒå¤šç§ï¼š
        # 1. UUIDæ ¼å¼ï¼š__REMOVED_API_KEY__
        # 2. ç«å±±å¼•æ“æ ¼å¼ï¼šåŒ…å«å­—æ¯æ•°å­—å’Œä¸‹åˆ’çº¿çš„å­—ç¬¦ä¸²
        elif len(key) == 36 and key.count('-') == 4:
            # éªŒè¯UUIDæ ¼å¼ï¼š__REMOVED_API_KEY__
            import re
            uuid_pattern = re.compile(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', re.IGNORECASE)
            if uuid_pattern.match(key):
                logger.debug(f"âœ… æ£€æµ‹åˆ°æœ‰æ•ˆçš„è±†åŒ…APIå¯†é’¥ï¼ˆUUIDæ ¼å¼ï¼‰")
                return 'doubao'
        elif len(key) >= 20 and len(key) <= 50 and key.replace('_', '').replace('-', '').isalnum() and not key.startswith("sk-"):
            # ç«å±±å¼•æ“è±†åŒ…APIå¯†é’¥ï¼šå­—æ¯æ•°å­—å’Œä¸‹åˆ’çº¿ç»„åˆï¼Œé•¿åº¦åœ¨20-50ä¹‹é—´ï¼Œä½†ä¸ä»¥sk-å¼€å¤´
            logger.debug(f"âœ… æ£€æµ‹åˆ°æœ‰æ•ˆçš„è±†åŒ…APIå¯†é’¥ï¼ˆç«å±±å¼•æ“æ ¼å¼ï¼‰")
            return 'doubao'
        
        else:
            raise ValueError(f"æ— æ³•è¯†åˆ«çš„APIå¯†é’¥ç±»å‹: {key[:10]}...")
    
    @classmethod
    def validate_environment(cls) -> Dict[str, Any]:
        """éªŒè¯ç¯å¢ƒé…ç½®"""
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "providers": [],
            "speech_services": []
        }
        
        # æ£€æŸ¥è±†åŒ…é…ç½®ï¼ˆé¦–é€‰ï¼‰
        try:
            doubao_key = cls.get_doubao_key()
            if doubao_key:
                key_type = cls._validate_key(doubao_key)
                if key_type == 'doubao':
                    validation_result["providers"].append("doubao")
                    logger.info("âœ… è±†åŒ…é…ç½®æœ‰æ•ˆ")
        except Exception as e:
            validation_result["warnings"].append(f"è±†åŒ…é…ç½®é—®é¢˜: {e}")
            logger.warning(f"âš ï¸ è±†åŒ…é…ç½®é—®é¢˜: {e}")
        
        # æ£€æŸ¥Qwené…ç½®ï¼ˆå¤‡ç”¨ï¼‰
        try:
            qwen_key = cls.get_qwen_key()
            if qwen_key:
                key_type = cls._validate_key(qwen_key)
                if key_type == 'qwen':
                    validation_result["providers"].append("qwen")
                    logger.info("âœ… Qwené…ç½®æœ‰æ•ˆ")
        except Exception as e:
            validation_result["warnings"].append(f"Qwené…ç½®é—®é¢˜: {e}")
            logger.warning(f"âš ï¸ Qwené…ç½®é—®é¢˜: {e}")
        
        # æ£€æŸ¥Llamaé…ç½®ï¼ˆæœ€ç»ˆå¤‡ç”¨ï¼‰
        try:
            llama_key = cls.get_llama_key()
            if llama_key:
                key_type = cls._validate_key(llama_key)
                if key_type == 'llama':
                    validation_result["providers"].append("llama")
                    logger.info("âœ… Llamaé…ç½®æœ‰æ•ˆ")
        except Exception as e:
            validation_result["warnings"].append(f"Llamaé…ç½®é—®é¢˜: {e}")
            logger.warning(f"âš ï¸ Llamaé…ç½®é—®é¢˜: {e}")
        
        # æ£€æŸ¥æœ¬åœ°è¯­éŸ³æœåŠ¡
        if cls.USE_LOCAL_WHISPER:
            validation_result["speech_services"].append("local-whisper")
            logger.info("âœ… æœ¬åœ°Whisperå·²å¯ç”¨")
        
        if cls.USE_LOCAL_TTS:
            validation_result["speech_services"].append("local-tts")
            logger.info("âœ… æœ¬åœ°TTSå·²å¯ç”¨")
        
        # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªå¯ç”¨çš„æä¾›å•†
        if not validation_result["providers"]:
            validation_result["valid"] = False
            validation_result["errors"].append("æ²¡æœ‰å¯ç”¨çš„APIæä¾›å•†")
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„APIæä¾›å•†")
        
        return validation_result
    
    @classmethod
    def get_config_summary(cls) -> Dict[str, Any]:
        """è·å–é…ç½®æ‘˜è¦"""
        return {
            "doubao_configured": bool(cls.DOUBAO_API_KEY),
            "qwen_configured": bool(cls.QWEN_API_KEY),
            "llama_configured": bool(cls.LLAMA_API_KEY),
            "local_whisper_enabled": cls.USE_LOCAL_WHISPER,
            "local_tts_enabled": cls.USE_LOCAL_TTS,
            "doubao_primary_enabled": cls.USE_DOUBAO_PRIMARY,
            "qwen_fallback_enabled": cls.USE_QWEN_FALLBACK,
            "llama_fallback_enabled": cls.USE_LLAMA_FALLBACK,
            "prefer_doubao": cls.PREFER_DOUBAO,
            "auto_switch_enabled": cls.ENABLE_AUTO_SWITCH,
            "realtime_voice_enabled": cls.VOICE_CONFIG.get("use_realtime_voice", False)
        }
    
    @classmethod
    def get_doubao_key(cls) -> str:
        """è·å–è±†åŒ…APIå¯†é’¥"""
        # å…ˆä»ç¯å¢ƒå˜é‡è·å–ï¼Œå†ä»ç±»å±æ€§è·å–
        doubao_key = os.getenv("DOUBAO_API_KEY") or cls.DOUBAO_API_KEY
        
        # æ¸…ç†APIå¯†é’¥æ ¼å¼
        if doubao_key:
            doubao_key = doubao_key.strip()
            # ç§»é™¤å¯èƒ½çš„é¢å¤–å¼•å·
            if doubao_key.startswith('"') and doubao_key.endswith('"'):
                doubao_key = doubao_key[1:-1]
            if doubao_key.startswith("'") and doubao_key.endswith("'"):
                doubao_key = doubao_key[1:-1]
            
            logger.debug(f"ğŸ”‘ æ£€æŸ¥è±†åŒ…APIå¯†é’¥: {doubao_key[:8]}...")
            
            # ç®€åŒ–éªŒè¯é€»è¾‘ï¼šUUIDæ ¼å¼æˆ–é•¿åº¦åˆç†çš„å­—ç¬¦ä¸²
            if (len(doubao_key) == 36 and doubao_key.count('-') == 4) or (len(doubao_key) >= 20 and not doubao_key.startswith("sk-")):
                logger.debug(f"âœ… è±†åŒ…APIå¯†é’¥éªŒè¯æˆåŠŸ")
                return doubao_key
            else:
                logger.warning(f"âš ï¸ è±†åŒ…APIå¯†é’¥æ ¼å¼æ— æ•ˆ: é•¿åº¦={len(doubao_key)}, æ ¼å¼={doubao_key[:10]}")
        else:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°è±†åŒ…APIå¯†é’¥ï¼ˆç¯å¢ƒå˜é‡æˆ–é…ç½®ï¼‰")
        
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²è®©ä¸Šå±‚å¤„ç†
        return ""
    
    @classmethod
    def get_doubao_base_url(cls) -> str:
        """è·å–è±†åŒ…APIåŸºç¡€URL"""
        return cls.DOUBAO_API_BASE_URL
    
    @classmethod
    def get_doubao_realtime_url(cls) -> str:
        """è·å–è±†åŒ…å®æ—¶è¯­éŸ³URL"""
        return cls.DOUBAO_REALTIME_URL
    
    @classmethod
    def get_llama_key(cls) -> str:
        """è·å–Llama APIå¯†é’¥"""
        return cls.LLAMA_API_KEY
    
    @classmethod
    def get_llama_base_url(cls) -> str:
        """è·å–Llama APIåŸºç¡€URL"""
        return cls.LLAMA_API_BASE_URL
    
    @classmethod
    def get_qwen_key(cls) -> str:
        """è·å–Qwen APIå¯†é’¥"""
        # å…ˆä»ç¯å¢ƒå˜é‡è·å–ï¼Œå†ä»ç±»å±æ€§è·å–
        qwen_key = os.getenv("QWEN_API_KEY") or cls.QWEN_API_KEY
        
        # æ¸…ç†APIå¯†é’¥æ ¼å¼
        if qwen_key:
            qwen_key = qwen_key.strip()
            # ç§»é™¤å¯èƒ½çš„é¢å¤–å¼•å·
            if qwen_key.startswith('"') and qwen_key.endswith('"'):
                qwen_key = qwen_key[1:-1]
            if qwen_key.startswith("'") and qwen_key.endswith("'"):
                qwen_key = qwen_key[1:-1]
            
            logger.debug(f"ğŸ”‘ æ£€æŸ¥Qwen APIå¯†é’¥: {qwen_key[:10]}...")
            
            # ç®€åŒ–éªŒè¯é€»è¾‘ï¼šåªè¦æ˜¯sk-å¼€å¤´ä¸”é•¿åº¦åˆç†å°±è®¤ä¸ºæœ‰æ•ˆ
            if qwen_key.startswith("sk-") and len(qwen_key) >= 30:
                logger.debug(f"âœ… Qwen APIå¯†é’¥éªŒè¯æˆåŠŸ")
                return qwen_key
            else:
                logger.warning(f"âš ï¸ Qwen APIå¯†é’¥æ ¼å¼æ— æ•ˆ: é•¿åº¦={len(qwen_key)}, å‰ç¼€={qwen_key[:10]}")
        else:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°Qwen APIå¯†é’¥ï¼ˆç¯å¢ƒå˜é‡æˆ–é…ç½®ï¼‰")
        
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²è®©ä¸Šå±‚å¤„ç†
        return ""
    
    @classmethod
    def get_model_for_provider(cls, provider: str, function_type: str) -> str:
        """
        æ ¹æ®æä¾›å•†å’ŒåŠŸèƒ½ç±»å‹è·å–å¯¹åº”çš„æ¨¡å‹
        
        Args:
            provider: æä¾›å•†ç±»å‹ (doubao, qwen, æˆ– llama)
            function_type: åŠŸèƒ½ç±»å‹ (chat, analysis, speech_recognition, speech_synthesis, code, math, realtime_voice)
            
        Returns:
            å¯¹åº”çš„æ¨¡å‹åç§°
        """
        if provider not in cls.MODEL_CONFIG:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")
        
        model_mapping = cls.MODEL_CONFIG[provider]
        
        # å¤„ç†åŠŸèƒ½ç±»å‹æ˜ å°„ - è±†åŒ…ä¼˜å…ˆï¼Œæœ¬åœ°å¤‡ç”¨
        if function_type == "speech_to_text" or function_type == "speech_recognition":
            if provider == "doubao":
                return model_mapping.get("voice_recognition", "doubao-stt")
            else:
                return "local-whisper"  # éè±†åŒ…æœåŠ¡ä½¿ç”¨æœ¬åœ°Whisper
        elif function_type == "text_to_speech" or function_type == "speech_synthesis":
            if provider == "doubao":
                return model_mapping.get("voice_synthesis", "doubao-tts")
            else:
                return "local-tts"  # éè±†åŒ…æœåŠ¡ä½¿ç”¨æœ¬åœ°TTS
        elif function_type == "realtime_voice":
            if provider == "doubao":
                return model_mapping.get("realtime_voice", "Doubao-å®æ—¶è¯­éŸ³å¤§æ¨¡å‹")
            else:
                raise ValueError(f"{provider} ä¸æ”¯æŒå®æ—¶è¯­éŸ³åŠŸèƒ½")
        elif function_type == "code_generation":
            function_type = "code"
        elif function_type == "math_reasoning":
            function_type = "math"
        
        return model_mapping.get(function_type, model_mapping.get("chat"))
    
    @classmethod
    def get_qwen_chat_model(cls) -> str:
        """è·å–QwenèŠå¤©æ¨¡å‹"""
        return cls.get_model_for_provider("qwen", "chat")
    
    @classmethod
    def get_qwen_analysis_model(cls) -> str:
        """è·å–Qwenåˆ†ææ¨¡å‹"""
        return cls.get_model_for_provider("qwen", "analysis")
    
    @classmethod
    def get_qwen_interview_model(cls) -> str:
        """è·å–Qwené¢è¯•æ¨¡å‹"""
        return cls.get_model_for_provider("qwen", "interview")
    
    @classmethod
    def get_qwen_fallback_model(cls) -> str:
        """è·å–Qwenå¤‡ç”¨æ¨¡å‹"""
        return cls.get_model_for_provider("qwen", "fallback")
    
    @classmethod
    def get_llama_chat_model(cls) -> str:
        """è·å–LlamaèŠå¤©æ¨¡å‹ï¼ˆå¤‡ç”¨ï¼‰"""
        return cls.get_model_for_provider("llama", "chat")
    
    @classmethod
    def get_llama_analysis_model(cls) -> str:
        """è·å–Llamaåˆ†ææ¨¡å‹ï¼ˆå¤‡ç”¨ï¼‰"""
        return cls.get_model_for_provider("llama", "analysis")
    
    @classmethod
    def get_llama_interview_model(cls) -> str:
        """è·å–Llamaé¢è¯•æ¨¡å‹ï¼ˆå¤‡ç”¨ï¼‰"""
        return cls.get_model_for_provider("llama", "interview")
    
    @classmethod
    def get_llama_fallback_model(cls) -> str:
        """è·å–Llamaå¤‡ç”¨æ¨¡å‹"""
        return cls.get_model_for_provider("llama", "fallback")
    
    @classmethod
    def get_voice_config(cls) -> Dict[str, Any]:
        """è·å–è¯­éŸ³é…ç½® - å®Œå…¨æœ¬åœ°åŒ–ç‰ˆæœ¬"""
        return {
            "default_voice": os.getenv("TTS_DEFAULT_VOICE", cls.VOICE_CONFIG["default_voice"]),
            "default_speed": float(os.getenv("DEFAULT_SPEECH_SPEED", cls.VOICE_CONFIG["default_speed"])),
            "max_audio_size_mb": int(os.getenv("MAX_AUDIO_SIZE_MB", cls.VOICE_CONFIG["max_audio_size_mb"])),
            "supported_formats": cls.VOICE_CONFIG["supported_formats"],
            "tts_engine": cls.VOICE_CONFIG["tts_engine"],
            "whisper_model": cls.VOICE_CONFIG["whisper_model"],
            "use_local_services": True  # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°æœåŠ¡
        }
    
    @classmethod
    def get_local_whisper_config(cls) -> Dict[str, Any]:
        """è·å–æœ¬åœ°Whisperé…ç½®"""
        return {
            "use_local_whisper": cls.USE_LOCAL_WHISPER,
            "model_size": cls.LOCAL_WHISPER_MODEL,
            "device": cls.LOCAL_WHISPER_DEVICE,
            "compute_type": cls.LOCAL_WHISPER_COMPUTE_TYPE,
            "model_dir": cls.LOCAL_WHISPER_MODEL_DIR,
            "disable_online": cls.DISABLE_WHISPER_ONLINE
        }
    
    @classmethod
    def get_local_tts_config(cls) -> Dict[str, Any]:
        """è·å–æœ¬åœ°TTSé…ç½®"""
        return {
            "use_local_tts": cls.USE_LOCAL_TTS,
            "engine": cls.LOCAL_TTS_ENGINE,
            "voice_mapping": {
                "nova": "zh-CN-XiaoxiaoNeural",
                "echo": "zh-CN-YunxiNeural",
                "alloy": "zh-CN-XiaoyiNeural",
                "fable": "zh-CN-YunjianNeural",
                "onyx": "zh-CN-YunxiaNeural",
                "shimmer": "zh-CN-XiaoshuangNeural"
            }
        }
    
    @classmethod
    def get_server_config(cls) -> Dict[str, Any]:
        """è·å–æœåŠ¡å™¨é…ç½®"""
        return {
            "host": os.getenv("BACKEND_HOST", cls.SERVER_CONFIG["host"]),
            "backend_port": int(os.getenv("BACKEND_PORT", cls.SERVER_CONFIG["backend_port"])),
            "vision_port": int(os.getenv("VISION_PORT", cls.SERVER_CONFIG["vision_port"])),
            "frontend_port": int(os.getenv("FRONTEND_PORT", cls.SERVER_CONFIG["frontend_port"])),
            "debug": os.getenv("DEBUG", "true").lower() == "true"
        }
    
    @classmethod
    def get_service_status(cls) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€ä¿¡æ¯"""
        status = {
            "status": "healthy",
            "doubao_configured": False,
            "qwen_configured": False,
            "llama_configured": bool(cls.LLAMA_API_KEY),
            "fallback_enabled": cls.USE_LLAMA_FALLBACK,
            "auto_switch_enabled": cls.ENABLE_AUTO_SWITCH,
            "prefer_doubao": getattr(cls, 'PREFER_DOUBAO', True),
            "prefer_qwen": cls.PREFER_QWEN,
            "local_whisper_enabled": cls.USE_LOCAL_WHISPER,
            "local_tts_enabled": cls.USE_LOCAL_TTS,
            "models_configured": len(cls.MODEL_CONFIG)
        }
        
        # æ£€æŸ¥è±†åŒ…é…ç½®
        try:
            doubao_key = cls.get_doubao_key()
            status["doubao_configured"] = bool(doubao_key)
        except Exception:
            status["doubao_configured"] = False
        
        # æ£€æŸ¥Qwené…ç½®
        try:
            qwen_key = cls.get_qwen_key()
            status["qwen_configured"] = bool(qwen_key)
        except Exception:
            status["qwen_configured"] = False
        
        # è‡³å°‘éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„é…ç½®
        if not any([status["doubao_configured"], status["qwen_configured"], status["llama_configured"]]):
            status["status"] = "unhealthy"
        
        return status
    
    @classmethod
    def validate_config(cls) -> bool:
        """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        # è‡³å°‘éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„APIå¯†é’¥
        has_llama = bool(cls.LLAMA_API_KEY)
        has_qwen = False
        
        try:
            cls.get_qwen_key()
            has_qwen = True
        except:
            pass
        
        if not has_llama and not has_qwen:
            raise ValueError("è‡³å°‘éœ€è¦é…ç½®ä¸€ä¸ªæœ‰æ•ˆçš„APIå¯†é’¥ï¼ˆLlamaæˆ–Qwenï¼‰")
        
        return True
    
    @classmethod
    def print_config_summary(cls):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸš€ VITA è±†åŒ…ä¸“ä¸šè¯­éŸ³MVPä¸‰æ¨¡å‹æ¶æ„é…ç½®æ‘˜è¦")
        print("="*60)
        
        # ä¸‰æ¨¡å‹æ¶æ„çŠ¶æ€
        status = cls.get_service_status()
        summary = cls.get_config_summary()
        
        print(f"\nğŸ—ï¸  æ¶æ„çŠ¶æ€: {status['status']}")
        print(f"ğŸ¯ è±†åŒ…é…ç½®: {'å·²é…ç½® âœ…' if summary['doubao_configured'] else 'æœªé…ç½® âŒ'}")
        print(f"ğŸ¤– Qwené…ç½®: {'å·²é…ç½® âœ…' if summary['qwen_configured'] else 'æœªé…ç½® âŒ'}")
        print(f"ğŸ¤– Llamaé…ç½®: {'å·²é…ç½® âœ…' if summary['llama_configured'] else 'æœªé…ç½® âŒ'}")
        print(f"ğŸ”„ å¤‡ç”¨æ–¹æ¡ˆ: {'å¯ç”¨' if summary['qwen_fallback_enabled'] else 'ç¦ç”¨'}")
        print(f"âš¡ è‡ªåŠ¨åˆ‡æ¢: {'å¯ç”¨' if summary['auto_switch_enabled'] else 'ç¦ç”¨'}")
        print(f"ğŸ¯ ä¼˜å…ˆä½¿ç”¨: {'è±†åŒ…ä¸“ä¸šè¯­éŸ³MVP' if summary['prefer_doubao'] else 'Qwen/Llama'}")
        
        # è±†åŒ…ä¸“ä¸šè¯­éŸ³æœåŠ¡çŠ¶æ€
        print(f"\nğŸµ è±†åŒ…ä¸“ä¸šè¯­éŸ³æœåŠ¡é…ç½®:")
        print(f"  - ğŸš€ å®æ—¶å¯¹è¯: Doubao-Seed-1.6-flash (10msæé€Ÿ)")
        print(f"  - ğŸ¤ æµå¼è¯†åˆ«: Doubao-æµå¼è¯­éŸ³è¯†åˆ«")
        print(f"  - ğŸ”Š è¯­éŸ³åˆæˆ: Doubao-è¯­éŸ³åˆæˆ")
        print(f"  - ğŸ“ æ–‡ä»¶è¯†åˆ«: Doubao-å½•éŸ³æ–‡ä»¶è¯†åˆ«")
        print(f"  - ğŸ­ å£°éŸ³å¤åˆ»: Doubao-å£°éŸ³å¤åˆ»")
        print(f"  - ğŸ’» æœ¬åœ°Whisper: å¯ç”¨ âœ… (å¤‡ç”¨)")
        print(f"  - ğŸ”Š æœ¬åœ°TTS: å¯ç”¨ âœ… (å¤‡ç”¨)")
        print(f"  - ä¸»è¦æœåŠ¡: doubaoä¸“ä¸šè¯­éŸ³")
        print(f"  - å¤‡ç”¨æœåŠ¡: local")
        
        # è±†åŒ…æ¨¡å‹è¯¦ç»†é…ç½®
        print(f"\nğŸ“Œ è±†åŒ…æ¨¡å‹é…ç½®ï¼ˆä¸»è¦ï¼‰:")
        doubao_models = cls.MODEL_CONFIG.get("doubao", {})
        for task, model in doubao_models.items():
            print(f"  - {task}: {model}")
        
        # Qwenæ¨¡å‹é…ç½®
        print(f"\nğŸ“Œ Qwenæ¨¡å‹é…ç½®ï¼ˆäºŒçº§å¤‡ç”¨ï¼‰:")
        qwen_models = cls.MODEL_CONFIG.get("qwen", {})
        for task, model in qwen_models.items():
            print(f"  - {task}: {model}")
        
        # Llamaæ¨¡å‹é…ç½®
        print(f"\nğŸ“Œ Llamaæ¨¡å‹é…ç½®ï¼ˆæœ€ç»ˆå¤‡ç”¨ï¼‰:")
        llama_models = cls.MODEL_CONFIG.get("llama", {})
        for task, model in llama_models.items():
            print(f"  - {task}: {model}")
        
        # è¯­éŸ³åŠŸèƒ½ç‰¹æ€§
        print(f"\nğŸµ è±†åŒ…ä¸“ä¸šè¯­éŸ³åŠŸèƒ½:")
        print(f"  - âš¡ æé€Ÿå“åº”: 10ms TPOT")
        print(f"  - ğŸ”„ æµå¼è¯†åˆ«: å®æ—¶è¯­éŸ³è½¬æ–‡å­—")
        print(f"  - ğŸ­ å£°éŸ³å¤åˆ»: é«˜çº§è¯­éŸ³å…‹éš†")
        print(f"  - ğŸª æƒ…æ„Ÿåˆæˆ: æƒ…æ„ŸåŒ–è¯­éŸ³è¾“å‡º") 
        print(f"  - ğŸ¯ å¤šè¯´è¯äºº: æ™ºèƒ½è¯´è¯äººè¯†åˆ«")
        print(f"  - ğŸ”‡ å™ªéŸ³å¤„ç†: èƒŒæ™¯å™ªéŸ³æ¶ˆé™¤")
        
        print(f"\nğŸµ é»˜è®¤è¯­éŸ³: professional_female")
        print(f"ğŸŒ æœåŠ¡ç«¯å£: 8000")
        print(f"âœ… è±†åŒ…ä¸“ä¸šè¯­éŸ³ä¸ºé¦–é€‰ï¼Œæœ¬åœ°æœåŠ¡ä½œä¸ºå¤‡ç”¨")
        print(f"âœ… è±†åŒ…ä¸“ä¸šè¯­éŸ³MVPæ¶æ„ï¼Œæ™ºèƒ½ä¸‰çº§å¤‡ç”¨åˆ‡æ¢")
        print(f"âœ… æ”¯æŒç«¯åˆ°ç«¯ä¸“ä¸šè¯­éŸ³å¯¹è¯ï¼Œæé€Ÿ+ä¸“ä¸š+æ™ºèƒ½")
        print("="*60)


# å…¨å±€é…ç½®å®ä¾‹
config = VITAConfig()

# æ™ºèƒ½æ¨¡å‹é€‰æ‹©å™¨ - è±†åŒ…ä¸“ä¸šè¯­éŸ³MVPæ¶æ„ç‰ˆæœ¬
class ModelSelector:
    """æ™ºèƒ½æ¨¡å‹é€‰æ‹©å™¨ - è±†åŒ…ä¸“ä¸šè¯­éŸ³MVPæ¶æ„ç‰ˆæœ¬"""
    
    @staticmethod
    def get_best_model_for_task(task_type: str, complexity: str = "medium") -> str:
        """
        æ ¹æ®ä»»åŠ¡ç±»å‹å’Œå¤æ‚åº¦é€‰æ‹©æœ€ä½³æ¨¡å‹
        è±†åŒ…ä¸“ä¸šè¯­éŸ³MVPæ¶æ„ï¼šæé€Ÿå“åº”+æ·±åº¦æ€è€ƒ+ä¸“ä¸šè¯­éŸ³+å¤šæ¨¡æ€ç†è§£
        """
        # ä¸“ä¸šè¯­éŸ³è¯†åˆ«ä»»åŠ¡ï¼šé¦–é€‰Doubao-æµå¼è¯­éŸ³è¯†åˆ«
        if task_type in ["voice_recognition", "speech_to_text", "streaming_asr"]:
            try:
                return config.get_model_for_provider("doubao", "voice_recognition")  # Doubao-æµå¼è¯­éŸ³è¯†åˆ«
            except:
                return config.get_model_for_provider("qwen", "speech_recognition")  # é™çº§åˆ°æœ¬åœ°Whisper
        
        # ä¸“ä¸šè¯­éŸ³åˆæˆä»»åŠ¡ï¼šé¦–é€‰Doubao-è¯­éŸ³åˆæˆ
        elif task_type in ["voice_synthesis", "text_to_speech", "tts"]:
            try:
                return config.get_model_for_provider("doubao", "voice_synthesis")  # Doubao-è¯­éŸ³åˆæˆ
            except:
                return config.get_model_for_provider("qwen", "speech_synthesis")  # é™çº§åˆ°æœ¬åœ°TTS
        
        # æ–‡ä»¶è¯­éŸ³è¯†åˆ«ï¼šé¦–é€‰Doubao-å½•éŸ³æ–‡ä»¶è¯†åˆ«
        elif task_type in ["file_recognition", "audio_file_transcription"]:
            try:
                return config.get_model_for_provider("doubao", "voice_file_recognition")  # Doubao-å½•éŸ³æ–‡ä»¶è¯†åˆ«
            except:
                return config.get_model_for_provider("qwen", "speech_recognition")  # é™çº§åˆ°æœ¬åœ°
        
        # å£°éŸ³å¤åˆ»ä»»åŠ¡ï¼šä½¿ç”¨Doubao-å£°éŸ³å¤åˆ»
        elif task_type in ["voice_cloning", "voice_mimicking"]:
            try:
                return config.get_model_for_provider("doubao", "voice_cloning")  # Doubao-å£°éŸ³å¤åˆ»
            except:
                return config.get_model_for_provider("qwen", "fallback")  # é™çº§åˆ°åŸºç¡€æ¨¡å‹
        
        # å®æ—¶è¯­éŸ³äº¤äº’ä»»åŠ¡ï¼šé¦–é€‰Doubao-Seed-1.6-flash(10msæé€Ÿ)
        elif task_type in ["realtime_voice", "voice_interview", "interactive_speech", "real_time_chat"]:
            try:
                return config.get_model_for_provider("doubao", "realtime_voice")  # Doubao-Seed-1.6-flash
            except:
                return config.get_model_for_provider("qwen", "chat")  # é™çº§åˆ°Qwen
        
        # é¢è¯•å¯¹è¯ä»»åŠ¡ï¼šé¦–é€‰Doubao-Seed-1.6-thinking(æ€è€ƒèƒ½åŠ›å¤§å¹…æå‡)
        elif task_type in ["interview", "interview_chat", "assessment"]:
            try:
                return config.get_model_for_provider("doubao", "interview")  # Doubao-Seed-1.6-thinking
            except:
                return config.get_model_for_provider("qwen", "interview")  # é™çº§åˆ°Qwen
        
        # ä»£ç è¯„ä¼°ä»»åŠ¡ï¼šé¦–é€‰Doubao-Seed-1.6-thinking(Codingè¡¨ç°æ›´å¼º)
        elif task_type in ["code", "coding", "programming", "code_review"]:
            try:
                return config.get_model_for_provider("doubao", "code")  # Doubao-Seed-1.6-thinking
            except:
                return config.get_model_for_provider("qwen", "code")  # é™çº§åˆ°Qwenä¸“ä¸šä»£ç æ¨¡å‹
        
        # æ•°å­¦æ¨ç†ä»»åŠ¡ï¼šé¦–é€‰Doubao-Seed-1.6-thinking(Mathè¡¨ç°æ›´å¼º)
        elif task_type in ["math", "mathematics", "calculation", "reasoning"]:
            try:
                return config.get_model_for_provider("doubao", "math")  # Doubao-Seed-1.6-thinking
            except:
                return config.get_model_for_provider("qwen", "math")  # é™çº§åˆ°Qwenæ•°å­¦æ¨¡å‹
        
        # å¤šæ¨¡æ€é¢è¯•ä»»åŠ¡ï¼šé¦–é€‰Doubao-1.5-thinking-vision-pro(è§†è§‰æ·±åº¦æ€è€ƒ)
        elif task_type in ["multimodal_interview", "visual_interview", "image_analysis"]:
            try:
                return config.get_model_for_provider("doubao", "multimodal_interview")  # Doubao-1.5-thinking-vision-pro
            except:
                return config.get_model_for_provider("qwen", "vision")  # é™çº§åˆ°Qwen
        
        # è§†è§‰ç†è§£ä»»åŠ¡ï¼šé¦–é€‰Doubao-1.5-vision-pro
        elif task_type in ["vision", "image_understanding", "visual_qa"]:
            try:
                return config.get_model_for_provider("doubao", "vision")  # Doubao-1.5-vision-pro
            except:
                return config.get_model_for_provider("qwen", "vision")  # é™çº§åˆ°Qwen
        
        # é•¿æ–‡æœ¬å¤„ç†ï¼šé¦–é€‰Doubao-pro-256k(è¶…é•¿ä¸Šä¸‹æ–‡)
        elif task_type in ["long_context", "document_analysis", "long_text"]:
            try:
                return config.get_model_for_provider("doubao", "long_context")  # Doubao-pro-256k
            except:
                return config.get_model_for_provider("qwen", "long_context")  # é™çº§åˆ°Qwen
        
        # æ·±åº¦åˆ†æä»»åŠ¡ï¼šé¦–é€‰Doubao-Seed-1.6-thinking
        elif task_type in ["analysis", "deep_analysis", "reasoning"]:
            try:
                return config.get_model_for_provider("doubao", "analysis")  # Doubao-Seed-1.6-thinking
            except:
                return config.get_model_for_provider("qwen", "analysis")  # é™çº§åˆ°Qwen
        
        # é€šç”¨èŠå¤©ä»»åŠ¡ï¼šæ ¹æ®å¤æ‚åº¦é€‰æ‹©
        elif task_type in ["chat", "conversation", "general"]:
            if complexity == "high":
                try:
                    return config.get_model_for_provider("doubao", "interview")  # é«˜å¤æ‚åº¦ç”¨æ€è€ƒæ¨¡å‹
                except:
                    return config.get_model_for_provider("qwen", "chat")
            else:
                try:
                    return config.get_model_for_provider("doubao", "chat")  # æ™®é€šèŠå¤©ç”¨æé€Ÿæ¨¡å‹
                except:
                    return config.get_model_for_provider("qwen", "chat")
        
        # é»˜è®¤é€‰æ‹©ï¼šè±†åŒ…æé€ŸèŠå¤©æ¨¡å‹
        try:
            return config.get_model_for_provider("doubao", "chat")  # Doubao-Seed-1.6-flash
        except:
            try:
                return config.get_model_for_provider("qwen", "chat")  # é™çº§åˆ°Qwen
            except:
                return config.get_model_for_provider("llama", "chat")  # æœ€ç»ˆé™çº§åˆ°Llama
    
    @staticmethod
    def get_voice_model_for_task(voice_task: str) -> str:
        """
        ä¸“é—¨ä¸ºè¯­éŸ³ä»»åŠ¡é€‰æ‹©æ¨¡å‹
        """
        voice_model_map = {
            "realtime_recognition": "Doubao-æµå¼è¯­éŸ³è¯†åˆ«",
            "file_recognition": "Doubao-å½•éŸ³æ–‡ä»¶è¯†åˆ«", 
            "synthesis": "Doubao-è¯­éŸ³åˆæˆ",
            "voice_cloning": "Doubao-å£°éŸ³å¤åˆ»",
            "realtime_conversation": "Doubao-Seed-1.6-flash"
        }
        
        return voice_model_map.get(voice_task, "Doubao-Seed-1.6-flash")
    
    @staticmethod
    def get_provider_priority() -> list:
        """
        è·å–æä¾›å•†ä¼˜å…ˆçº§é¡ºåº
        """
        return ["doubao", "qwen", "llama"]
    
    @staticmethod 
    def is_voice_task(task_type: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºè¯­éŸ³ç›¸å…³ä»»åŠ¡
        """
        voice_tasks = [
            "voice_recognition", "speech_to_text", "streaming_asr",
            "voice_synthesis", "text_to_speech", "tts",
            "file_recognition", "audio_file_transcription",
            "voice_cloning", "voice_mimicking",
            "realtime_voice", "voice_interview", "interactive_speech"
        ]
        return task_type in voice_tasks


# å¯¼å‡ºé…ç½®
__all__ = ["VITAConfig", "config", "ModelSelector"]