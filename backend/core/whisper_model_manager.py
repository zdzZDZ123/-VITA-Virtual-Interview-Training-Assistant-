"""
Whisperæ¨¡å‹ç®¡ç†å™¨
è´Ÿè´£è‡ªåŠ¨æ£€æµ‹ã€ä¸‹è½½å’Œç®¡ç†Whisperæ¨¡å‹
"""

import os
import sys
import logging
from pathlib import Path
from typing import Optional, Dict, Any
import json
import shutil
import asyncio
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

class WhisperModelManager:
    """Whisperæ¨¡å‹ç®¡ç†å™¨"""
    
    # æ¨¡å‹é…ç½®
    MODEL_SIZES = {
        "tiny": {"size_mb": 39, "repo": "Systran/faster-whisper-tiny"},
        "base": {"size_mb": 74, "repo": "Systran/faster-whisper-base"}, 
        "small": {"size_mb": 244, "repo": "Systran/faster-whisper-small"},
        "medium": {"size_mb": 769, "repo": "Systran/faster-whisper-medium"},
        "large": {"size_mb": 1550, "repo": "Systran/faster-whisper-large-v1"},
        "large-v2": {"size_mb": 1550, "repo": "Systran/faster-whisper-large-v2"},
        "large-v3": {"size_mb": 1550, "repo": "Systran/faster-whisper-large-v3"}
    }
    
    def __init__(self, model_dir: str = "whisper_download"):
        """åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨"""
        self.project_root = Path(__file__).parent.parent.parent
        self.model_dir = self.project_root / model_dir
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¸‹è½½çŠ¶æ€
        self.download_in_progress = False
        self.download_progress = {}
        
        logger.info(f"ğŸ“¦ WhisperModelManager åˆå§‹åŒ–å®Œæˆ, æ¨¡å‹ç›®å½•: {self.model_dir}")
    
    def find_local_model(self, model_size: str) -> Optional[Path]:
        """æŸ¥æ‰¾æœ¬åœ°æ¨¡å‹"""
        # å¤šä¸ªå¯èƒ½çš„ä½ç½®
        potential_paths = [
            self.model_dir / model_size,
            Path.home() / ".cache" / "huggingface" / "hub" / f"__REMOVED_API_KEY__{model_size}",
            Path.cwd() / "whisper_download" / model_size,
        ]
        
        for path in potential_paths:
            if self._validate_model_path(path):
                logger.info(f"âœ… æ‰¾åˆ°æœ¬åœ°æ¨¡å‹: {path}")
                return path
        
        logger.warning(f"âŒ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ {model_size}")
        logger.info(f"ğŸ“ æœç´¢è·¯å¾„åŒ…æ‹¬: {[str(p) for p in potential_paths]}")
        return None
    
    def _validate_model_path(self, path: Path) -> bool:
        """éªŒè¯æ¨¡å‹è·¯å¾„æ˜¯å¦æœ‰æ•ˆ"""
        if not path.exists() or not path.is_dir():
            return False
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        required_files = ["config.json"]
        optional_files = ["model.bin", "tokenizer.json", "vocabulary.txt"]
        
        # å¿…é¡»æœ‰config.json
        if not all((path / f).exists() for f in required_files):
            return False
        
        # è‡³å°‘æœ‰ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶
        has_model = any((path / f).exists() for f in optional_files)
        return has_model
    
    async def ensure_model_available(self, model_size: str, auto_download: bool = True) -> Optional[Path]:
        """ç¡®ä¿æ¨¡å‹å¯ç”¨ï¼Œå¿…è¦æ—¶è‡ªåŠ¨ä¸‹è½½"""
        # å…ˆæ£€æŸ¥æœ¬åœ°
        local_path = self.find_local_model(model_size)
        if local_path:
            return local_path
        
        if not auto_download:
            logger.warning(f"âš ï¸ æ¨¡å‹ {model_size} ä¸å­˜åœ¨ï¼Œä¸”è‡ªåŠ¨ä¸‹è½½å·²ç¦ç”¨")
            return None
        
        # è‡ªåŠ¨ä¸‹è½½
        logger.info(f"ğŸ“¥ å¼€å§‹è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ {model_size}")
        success = await self.download_model_async(model_size)
        
        if success:
            return self.model_dir / model_size
        else:
            logger.error(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
            return None
    
    async def download_model_async(self, model_size: str) -> bool:
        """å¼‚æ­¥ä¸‹è½½æ¨¡å‹"""
        if self.download_in_progress:
            logger.warning("â³ å·²æœ‰ä¸‹è½½ä»»åŠ¡è¿›è¡Œä¸­")
            return False
        
        if model_size not in self.MODEL_SIZES:
            logger.error(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹å¤§å°: {model_size}")
            return False
        
        self.download_in_progress = True
        self.download_progress[model_size] = 0
        
        try:
            # è¿è¡Œä¸‹è½½è„šæœ¬
            script_path = self.project_root / "scripts" / "download_faster_whisper.py"
            
            if not script_path.exists():
                logger.error(f"âŒ ä¸‹è½½è„šæœ¬ä¸å­˜åœ¨: {script_path}")
                return False
            
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥çš„ä¸‹è½½æ“ä½œ
            loop = asyncio.get_running_loop()
            with ThreadPoolExecutor() as executor:
                result = await loop.run_in_executor(
                    executor,
                    self._run_download_script,
                    str(script_path),
                    model_size
                )
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
            return False
        finally:
            self.download_in_progress = False
    
    def _run_download_script(self, script_path: str, model_size: str) -> bool:
        """è¿è¡Œä¸‹è½½è„šæœ¬ï¼ˆåŒæ­¥ï¼‰"""
        import subprocess
        
        try:
            # æ„å»ºå‘½ä»¤
            cmd = [sys.executable, script_path, model_size, "--verify"]
            
            logger.info(f"ğŸš€ æ‰§è¡Œä¸‹è½½å‘½ä»¤: {' '.join(cmd)}")
            
            # æ‰§è¡Œä¸‹è½½
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=str(self.project_root)
            )
            
            if result.returncode == 0:
                logger.info(f"âœ… æ¨¡å‹ {model_size} ä¸‹è½½æˆåŠŸ")
                return True
            else:
                logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œä¸‹è½½è„šæœ¬å¤±è´¥: {e}")
            return False
    
    def get_model_info(self, model_size: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        if model_size not in self.MODEL_SIZES:
            return {}
        
        info = self.MODEL_SIZES[model_size].copy()
        info["installed"] = self.find_local_model(model_size) is not None
        info["path"] = str(self.find_local_model(model_size) or "")
        
        return info
    
    def list_available_models(self) -> Dict[str, Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        models = {}
        for size in self.MODEL_SIZES:
            models[size] = self.get_model_info(size)
        return models
    
    def cleanup_cache(self) -> int:
        """æ¸…ç†ç¼“å­˜ï¼Œè¿”å›é‡Šæ”¾çš„å­—èŠ‚æ•°"""
        freed_bytes = 0
        
        # æ¸…ç† huggingface ç¼“å­˜
        hf_cache = Path.home() / ".cache" / "huggingface"
        if hf_cache.exists():
            for model_dir in hf_cache.glob("**/__REMOVED_API_KEY__*"):
                try:
                    size = sum(f.stat().st_size for f in model_dir.rglob("*") if f.is_file())
                    shutil.rmtree(model_dir)
                    freed_bytes += size
                    logger.info(f"ğŸ§¹ æ¸…ç†ç¼“å­˜: {model_dir.name}")
                except Exception as e:
                    logger.error(f"æ¸…ç†å¤±è´¥: {e}")
        
        return freed_bytes


# å…¨å±€å®ä¾‹
_model_manager: Optional[WhisperModelManager] = None

def get_model_manager() -> WhisperModelManager:
    """è·å–å…¨å±€æ¨¡å‹ç®¡ç†å™¨å®ä¾‹"""
    global _model_manager
    if _model_manager is None:
        _model_manager = WhisperModelManager()
    return _model_manager 