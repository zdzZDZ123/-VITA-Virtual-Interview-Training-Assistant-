"""
è¯­éŸ³æœåŠ¡æ¨¡å—
æä¾›æœ¬åœ°Whisperè¯­éŸ³è¯†åˆ«å’ŒTTSè¯­éŸ³åˆæˆåŠŸèƒ½
å®Œå…¨ç‹¬ç«‹äºOpenAI API
"""

import os
import tempfile
import asyncio
import socket
import subprocess
from typing import Optional, Dict, Any, AsyncGenerator, List
from pathlib import Path
import aiofiles
import httpx
import logging
import io
from fastapi import HTTPException
from core.config import config, ModelSelector
from .tts_service import get_tts_service
from core.whisper_model_manager import get_model_manager

# è®¾ç½®logger
logger = logging.getLogger(__name__)

def check_network_connection(timeout: float = 5.0) -> bool:
    """æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦å¯ç”¨"""
    try:
        # å°è¯•è¿æ¥Google DNS
        socket.create_connection(("8.8.8.8", 53), timeout)
        return True
    except (socket.timeout, socket.error):
        try:
            # å¤‡ç”¨ï¼šå°è¯•è¿æ¥Cloudflare DNS
            socket.create_connection(("1.1.1.1", 53), timeout)
            return True
        except (socket.timeout, socket.error):
            return False

def find_local_whisper_model(model_size: str, model_dir: str) -> Optional[Path]:
    """æŸ¥æ‰¾æœ¬åœ°Whisperæ¨¡å‹ç›®å½•"""
    # ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•æŸ¥æ‰¾
    project_root = Path(__file__).parent.parent.parent
    potential_paths = [
        # é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„whisper_download
        project_root / model_dir / model_size,
        # å½“å‰å·¥ä½œç›®å½•ä¸‹çš„whisper_download
        Path.cwd() / model_dir / model_size,
        # ç›´æ¥åœ¨å½“å‰ç›®å½•
        Path(model_dir) / model_size,
        # ç»å¯¹è·¯å¾„
        Path(model_dir) if Path(model_dir).is_absolute() else None
    ]
    
    for path in potential_paths:
        if path and path.exists() and path.is_dir():
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„æ¨¡å‹æ–‡ä»¶
            required_files = ['config.json']  # faster-whisperåŸºæœ¬è¦æ±‚
            if all((path / f).exists() for f in required_files):
                logger.info(f"âœ… å‘ç°æœ¬åœ°æ¨¡å‹: {path}")
                return path
    
    return None

# æœ¬åœ°Whisperç›¸å…³å¯¼å…¥
try:
    from faster_whisper import WhisperModel
    import torch
    FASTER_WHISPER_AVAILABLE = True
    logger.info("âœ… faster-whisper å¯ç”¨")
except ImportError:
    FASTER_WHISPER_AVAILABLE = False
    logger.warning("âš ï¸ faster-whisper æœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨æ ‡å‡†whisper")

# å¤‡ç”¨ï¼šå°è¯•ä½¿ç”¨æ ‡å‡†whisper
if not FASTER_WHISPER_AVAILABLE:
    try:
        import whisper
        WHISPER_AVAILABLE = True
        logger.info("âœ… æ ‡å‡†whisper å¯ç”¨")
    except ImportError:
        WHISPER_AVAILABLE = False
        logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„Whisperå®ç°")
else:
    # å³ä½¿æœ‰faster-whisperï¼Œä¹Ÿå°è¯•å¯¼å…¥æ ‡å‡†whisperä½œä¸ºå¤‡ç”¨
    try:
        import whisper
        WHISPER_AVAILABLE = True
        logger.debug("ğŸ“¦ æ ‡å‡†whisperä¹Ÿå¯ç”¨ä½œå¤‡ç”¨")
    except ImportError:
        WHISPER_AVAILABLE = False
        logger.debug("âš ï¸ æ ‡å‡†whisperä¸å¯ç”¨ï¼Œä»…æœ‰faster-whisper")

class SpeechService:
    """è¯­éŸ³æœåŠ¡ç±»ï¼Œä½¿ç”¨æœ¬åœ°Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«
    
    å®Œå…¨ç‹¬ç«‹äºäº‘ç«¯APIï¼Œæä¾›æœ¬åœ°åŒ–çš„è¯­éŸ³å¤„ç†èƒ½åŠ›
    """
    
    def __init__(self):
        try:
            voice_config = config.get_voice_config()
            self.supported_formats = voice_config["supported_formats"]
            self.max_audio_size_mb = voice_config["max_audio_size_mb"]
            
            # åˆå§‹åŒ–æœ¬åœ°Whisperæ¨¡å‹
            self.local_whisper = None
            self.local_whisper_config = config.get_local_whisper_config()
            
            # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°Whisper
            if FASTER_WHISPER_AVAILABLE or WHISPER_AVAILABLE:
                self._init_local_whisper()
            else:
                raise Exception("æ²¡æœ‰å¯ç”¨çš„Whisperå®ç°ï¼Œè¯·å®‰è£… faster-whisper æˆ– whisper")
            
            # åˆå§‹åŒ–æ–°çš„TTSæœåŠ¡
            self.tts_service = get_tts_service()
            
            logger.info("âœ… SpeechService åˆå§‹åŒ–æˆåŠŸ (çº¯æœ¬åœ°Whisper)")
        except Exception as e:
            logger.error(f"âŒ SpeechService åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _init_local_whisper(self):
        """åˆå§‹åŒ–æœ¬åœ°Whisperæ¨¡å‹ - ä½¿ç”¨æ–°çš„æ¨¡å‹ç®¡ç†å™¨"""
        try:
            model_size = self.local_whisper_config["model_size"]
            device = self.local_whisper_config["device"]
            compute_type = self.local_whisper_config["compute_type"]
            disable_online = self.local_whisper_config.get("disable_online", False)
            
            # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
            if device == "auto":
                if FASTER_WHISPER_AVAILABLE and torch.cuda.is_available():
                    device = "cuda"
                    logger.info("ğŸš€ æ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
                else:
                    device = "cpu"
                    compute_type = "int8"  # CPUä½¿ç”¨int8æ›´å¿«
                    logger.info("ğŸ’» ä½¿ç”¨CPUè¿›è¡Œæ¨ç†")
            
            logger.info(f"â³ æ­£åœ¨åŠ è½½æœ¬åœ°Whisperæ¨¡å‹: {model_size}, è®¾å¤‡: {device}, ç²¾åº¦: {compute_type}")
            
            # ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨æŸ¥æ‰¾æˆ–ä¸‹è½½æ¨¡å‹
            model_manager = get_model_manager()
            
            # å…ˆæ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰æ¨¡å‹
            local_model_path = model_manager.find_local_model(model_size)
            
            if local_model_path:
                # å°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹
                if FASTER_WHISPER_AVAILABLE:
                    if self._try_local_model_path(local_model_path, device, compute_type):
                        logger.info(f"âœ… ä½¿ç”¨æœ¬åœ°faster-whisperæ¨¡å‹: {local_model_path}")
                        return
            else:
                # æœ¬åœ°æ²¡æœ‰æ¨¡å‹ï¼Œæç¤ºç”¨æˆ·
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ {model_size}")
                logger.info("ğŸ’¡ æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–æ¨¡å‹ï¼š")
                logger.info(f"   1. è¿è¡Œ: python scripts/download_faster_whisper.py {model_size}")
                logger.info(f"   2. æˆ–è€…åœ¨å¯åŠ¨æ—¶ç­‰å¾…è‡ªåŠ¨ä¸‹è½½ï¼ˆéœ€è¦ç½‘ç»œè¿æ¥ï¼‰")
            
            # ç­–ç•¥2: å°è¯•ä»ç³»ç»Ÿç¼“å­˜åŠ è½½
            if FASTER_WHISPER_AVAILABLE:
                if self._try_faster_whisper_cached(model_size, device, compute_type):
                    logger.info(f"âœ… ä½¿ç”¨ç¼“å­˜çš„faster-whisperæ¨¡å‹: {model_size}")
                    return
            
            # ç­–ç•¥3: åœ¨çº¿ä¸‹è½½ (ä»…åœ¨ç½‘ç»œå¯ç”¨ä¸”æœªç¦ç”¨æ—¶)
            if not disable_online and check_network_connection():
                logger.info("ğŸŒ ç½‘ç»œå¯ç”¨ï¼Œå°è¯•åœ¨çº¿ä¸‹è½½æ¨¡å‹...")
                if FASTER_WHISPER_AVAILABLE:
                    if self._try_faster_whisper_online(model_size, device, compute_type):
                        logger.info(f"âœ… åœ¨çº¿ä¸‹è½½faster-whisperæ¨¡å‹æˆåŠŸ: {model_size}")
                        # ä¿å­˜è·¯å¾„ä¿¡æ¯ä¾›ä¸‹æ¬¡ä½¿ç”¨
                        logger.info("ğŸ’¡ æ¨¡å‹å·²ä¸‹è½½åˆ°ç³»ç»Ÿç¼“å­˜ï¼Œä¸‹æ¬¡å¯åŠ¨å°†ç›´æ¥ä½¿ç”¨")
                        return
            else:
                if disable_online:
                    logger.info("ğŸš« åœ¨çº¿ä¸‹è½½å·²ç¦ç”¨ (DISABLE_WHISPER_ONLINE=true)")
                else:
                    logger.info("ğŸŒ ç½‘ç»œä¸å¯ç”¨ï¼Œæ— æ³•ä¸‹è½½æ¨¡å‹")
            
            # ç­–ç•¥4: ä½¿ç”¨æ ‡å‡†whisperä½œä¸ºæœ€ç»ˆå¤‡ç”¨
            if WHISPER_AVAILABLE:
                logger.info("ğŸ“¦ ä½¿ç”¨æ ‡å‡†whisperä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
                if self._try_standard_whisper(model_size):
                    logger.info(f"âœ… ä½¿ç”¨æ ‡å‡†whisperæ¨¡å‹: {model_size}")
                    logger.info("ğŸ’¡ å»ºè®®ä¸‹è½½faster-whisperæ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½")
                    return
            
            # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ - ä¸ä¸­æ–­å¯åŠ¨ï¼Œåªè®°å½•è­¦å‘Š
            logger.warning("âš ï¸ æ— æ³•åŠ è½½ä»»ä½•Whisperæ¨¡å‹ï¼Œè¯­éŸ³è¯†åˆ«åŠŸèƒ½å°†è¢«ç¦ç”¨")
            logger.info("ğŸ’¡ æ‚¨å¯ä»¥ç¨åé€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ç”¨è¯­éŸ³åŠŸèƒ½ï¼š")
            logger.info("   1. ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸")
            logger.info(f"   2. è¿è¡Œ: python -c \"from faster_whisper import WhisperModel; WhisperModel('{model_size}')\"")
            logger.info("   3. é‡å¯æœåŠ¡")
            self.local_whisper = None
            
        except Exception as e:
            logger.warning(f"âš ï¸ æœ¬åœ°Whisperæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.info("ğŸš€ æœåŠ¡å°†åœ¨ç¦ç”¨è¯­éŸ³è¯†åˆ«çš„æƒ…å†µä¸‹ç»§ç»­å¯åŠ¨")
            self.local_whisper = None
        
    def _try_local_model_path(self, model_path: Path, device: str, compute_type: str) -> bool:
        """å°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„åŠ è½½faster-whisper"""
        try:
            logger.info(f"ğŸ“‚ ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„: {model_path}")
            self.local_whisper = WhisperModel(
                str(model_path), 
                device=device, 
                compute_type=compute_type,
                local_files_only=True
            )
            self.whisper_type = "faster_whisper_local"
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ æœ¬åœ°æ¨¡å‹è·¯å¾„åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _try_faster_whisper_cached(self, model_size: str, device: str, compute_type: str) -> bool:
        """å°è¯•ä½¿ç”¨ç³»ç»Ÿç¼“å­˜çš„faster-whisperæ¨¡å‹"""
        try:
            # é™é»˜æ¨¡å¼å°è¯•ï¼Œé¿å…è­¦å‘Šæ—¥å¿—
            import warnings
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                self.local_whisper = WhisperModel(
                    model_size, 
                    device=device, 
                    compute_type=compute_type,
                    local_files_only=True
                )
            self.whisper_type = "faster_whisper_cached"
            return True
        except Exception:
            # é™é»˜å¤±è´¥ï¼Œä¸è¾“å‡ºè­¦å‘Š
            return False
    
    def _try_faster_whisper_online(self, model_size: str, device: str, compute_type: str) -> bool:
        """å°è¯•ä½¿ç”¨faster-whisperåœ¨çº¿æ¨¡å¼"""
        try:
            # åœ¨çº¿ä¸‹è½½å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œç»™ç”¨æˆ·æç¤º
            logger.info(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½faster-whisperæ¨¡å‹: {model_size} (é¦–æ¬¡ä½¿ç”¨éœ€è¦æ—¶é—´)...")
            self.local_whisper = WhisperModel(
                model_size, 
                device=device, 
                compute_type=compute_type,
                local_files_only=False  # å…è®¸åœ¨çº¿ä¸‹è½½
            )
            self.whisper_type = "faster_whisper_online"
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ åœ¨çº¿ä¸‹è½½faster-whisperæ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def _try_standard_whisper(self, model_size: str) -> bool:
        """å°è¯•ä½¿ç”¨æ ‡å‡†whisper"""
        try:
            # æ ‡å‡†whisperé¦–æ¬¡ä¸‹è½½ä¹Ÿå¯èƒ½éœ€è¦æ—¶é—´
            logger.info(f"ğŸ“¦ åŠ è½½æ ‡å‡†whisperæ¨¡å‹: {model_size}...")
            self.local_whisper = whisper.load_model(model_size)
            self.whisper_type = "standard_whisper"
            logger.info(f"ğŸ‰ æœ¬åœ°Whisperæ¨¡å‹åŠ è½½æˆåŠŸï¼(æ ‡å‡†whisper - {model_size})")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ æ ‡å‡†whisperåŠ è½½å¤±è´¥: {e}")
            return False
    
    async def speech_to_text(
        self, 
        audio_data: bytes, 
        language: Optional[str] = None,
        prompt: Optional[str] = None,
        filename: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        è¯­éŸ³è½¬æ–‡å­— - çº¯æœ¬åœ°Whisperå®ç°
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            language: è¯­è¨€ä»£ç  (å¯é€‰)
            prompt: æç¤ºæ–‡æœ¬ï¼Œæœ‰åŠ©äºæé«˜è¯†åˆ«å‡†ç¡®ç‡
            filename: åŸå§‹æ–‡ä»¶åï¼Œç”¨äºç¡®å®šéŸ³é¢‘æ ¼å¼
            
        Returns:
            åŒ…å«è½¬å½•æ–‡æœ¬å’Œç½®ä¿¡åº¦çš„å­—å…¸
        """
        try:
            # éªŒè¯éŸ³é¢‘æ•°æ®
            await self.validate_audio(audio_data)
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œæ ¹æ®åŸæ–‡ä»¶åå†³å®šåç¼€
            suffix = ".wav"
            if filename and "." in filename:
                suffix = filename[filename.rfind(".") :]
            with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as temp_file:
                temp_file.write(audio_data)
                temp_file_path = temp_file.name
            
            try:
                # ä½¿ç”¨æœ¬åœ°Whisperæ¨¡å‹
                if self.local_whisper is None:
                    return {
                        "text": "[è¯­éŸ³è¯†åˆ«åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨]",
                        "language": "zh",
                        "duration": 0,
                        "words": [],
                        "confidence": 0.0,
                        "error": "Whisperæ¨¡å‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ‰‹åŠ¨å®‰è£…æ¨¡å‹"
                    }
                
                return await self._transcribe_with_local_whisper(
                    temp_file_path, language, prompt
                )
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_file_path)
                except OSError:
                    pass
                    
        except Exception as e:
            logger.error(f"âŒ è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {str(e)}")
    
    async def _transcribe_with_local_whisper(
        self, 
        audio_file_path: str, 
        language: Optional[str] = None,
        prompt: Optional[str] = None
    ) -> Dict[str, Any]:
        """ä½¿ç”¨æœ¬åœ°Whisperæ¨¡å‹è¿›è¡Œè½¬å½•"""
        try:
            logger.info(f"ğŸ¯ ä½¿ç”¨æœ¬åœ°Whisperæ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ« ({self.whisper_type})")
            
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„è½¬å½•æ“ä½œ
            loop = asyncio.get_running_loop()
            
            # å…¼å®¹ä¸åŒçš„ faster-whisper åŠ è½½ç­–ç•¥ (local / cached / online)
            if self.whisper_type and self.whisper_type.startswith("faster_whisper"):
                # faster-whisperå®ç°
                segments, info = await loop.run_in_executor(
                    None,
                    lambda: self.local_whisper.transcribe(
                        audio_file_path,
                        language=language,
                        initial_prompt=prompt,
                        beam_size=5,
                        word_timestamps=True
                    )
                )
                
                # æå–æ–‡æœ¬å’Œè¯çº§æ—¶é—´æˆ³
                text_parts = []
                words = []
                
                for segment in segments:
                    text_parts.append(segment.text)
                    if hasattr(segment, 'words') and segment.words:
                        for word in segment.words:
                            words.append({
                                "word": word.word,
                                "start": word.start,
                                "end": word.end,
                                "probability": getattr(word, 'probability', 0.95)
                            })
                
                full_text = "".join(text_parts).strip()
                
                result = {
                    "text": full_text,
                    "language": info.language,
                    "duration": info.duration,
                    "words": words,
                    "confidence": 0.95  # faster-whisperé»˜è®¤ç½®ä¿¡åº¦
                }
            else:
                # æ ‡å‡†whisperå®ç°
                result_data = await loop.run_in_executor(
                    None,
                    lambda: self.local_whisper.transcribe(
                        audio_file_path,
                        language=language,
                        initial_prompt=prompt,
                        word_timestamps=True
                    )
                )
                
                result = {
                    "text": result_data["text"].strip(),
                    "language": result_data.get("language", language or "zh"),
                    "duration": len(result_data.get("segments", [])) * 30,  # ä¼°ç®—æ—¶é•¿
                    "words": [],  # æ ‡å‡†whisperçš„è¯çº§æ—¶é—´æˆ³æ ¼å¼ä¸åŒ
                    "confidence": 0.90  # æ ‡å‡†whisperé»˜è®¤ç½®ä¿¡åº¦
                }
                
                # æå–åˆ†æ®µä¿¡æ¯
                if "segments" in result_data:
                    for segment in result_data["segments"]:
                        if "words" in segment:
                            for word in segment["words"]:
                                result["words"].append({
                                    "word": word.get("word", ""),
                                    "start": word.get("start", 0),
                                    "end": word.get("end", 0),
                                    "probability": word.get("probability", 0.90)
                                })
            
            logger.info(f"âœ… æœ¬åœ°Whisperè¯†åˆ«å®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(result['text'])}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°Whisperè½¬å½•å¤±è´¥: {e}")
            raise Exception(f"æœ¬åœ°Whisperè½¬å½•å¤±è´¥: {e}")
    
    async def text_to_speech(
        self,
        text: str,
        voice: str = "nova",
        response_format: str = "mp3",
        speed: float = 1.0,
        output_format: str = None
    ) -> bytes:
        """
        æ–‡å­—è½¬è¯­éŸ³ - ä½¿ç”¨æœ¬åœ°TTSæœåŠ¡
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            voice: å£°éŸ³ç±»å‹
            response_format: éŸ³é¢‘æ ¼å¼ (å·²å¼ƒç”¨ï¼Œä½¿ç”¨output_format)
            speed: è¯­éŸ³é€Ÿåº¦
            output_format: è¾“å‡ºæ ¼å¼ ("mp3" æˆ– "wav")
            
        Returns:
            éŸ³é¢‘æ•°æ®ï¼ˆå­—èŠ‚ï¼‰
        """
        try:
            logger.info(f"ğŸµ ä½¿ç”¨æœ¬åœ°TTSæœåŠ¡è¿›è¡Œè¯­éŸ³åˆæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
            
            # ç¡®å®šè¾“å‡ºæ ¼å¼
            format_to_use = output_format or response_format or "mp3"
            
            # ä½¿ç”¨æ–°çš„ç»Ÿä¸€TTSæœåŠ¡ï¼Œä¼ é€’æ ¼å¼å‚æ•°
            if hasattr(self.tts_service, 'synthesize_with_format'):
                audio_data = await self.tts_service.synthesize_with_format(
                    text=text,
                    voice=voice,
                    speed=speed,
                    output_format=format_to_use
                )
            else:
                # å¤‡ç”¨ï¼šå°è¯•ç›´æ¥è°ƒç”¨å¼•æ“
                from core.tts_engines.edge_engine import EdgeTTSEngine
                engine = EdgeTTSEngine()
                if engine.is_available():
                    audio_data = await engine.synthesize(
                        text=text,
                        voice=voice,
                        speed=speed,
                        output_format=format_to_use
                    )
                else:
                    # æœ€ç»ˆå¤‡ç”¨ï¼šä½¿ç”¨åŸæœ‰æ–¹æ³•
                    audio_data = await self.tts_service.synthesize(
                        text=text,
                        voice=voice,
                        speed=speed
                    )
            
            logger.info(f"âœ… æœ¬åœ°TTSåˆæˆå®Œæˆï¼ŒéŸ³é¢‘å¤§å°: {len(audio_data)} å­—èŠ‚, æ ¼å¼: {format_to_use}")
            return audio_data
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°TTSåˆæˆå¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")
    
    async def validate_audio(self, audio_data: bytes) -> None:
        """éªŒè¯éŸ³é¢‘æ•°æ®"""
        if not audio_data:
            logger.warning("âŒ éŸ³é¢‘æ•°æ®ä¸ºç©º")
            raise HTTPException(status_code=400, detail="éŸ³é¢‘æ•°æ®ä¸ºç©º")
        
        if len(audio_data) < 100:  # å°äº100å­—èŠ‚è®¤ä¸ºæ— æ•ˆ
            logger.warning(f"âŒ éŸ³é¢‘æ•°æ®è¿‡å°: {len(audio_data)} bytes")
            raise HTTPException(status_code=400, detail="éŸ³é¢‘æ•°æ®è¿‡å°ï¼Œå¯èƒ½æ˜¯æ— æ•ˆå½•éŸ³")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        size_mb = len(audio_data) / (1024 * 1024)
        if size_mb > self.max_audio_size_mb:
            logger.warning(f"âŒ éŸ³é¢‘æ–‡ä»¶è¿‡å¤§: {size_mb:.1f}MB")
            raise HTTPException(
                status_code=413, 
                detail=f"éŸ³é¢‘æ–‡ä»¶è¿‡å¤§: {size_mb:.1f}MB > {self.max_audio_size_mb}MB"
            )
        
        logger.debug(f"âœ… éŸ³é¢‘éªŒè¯é€šè¿‡ï¼Œå¤§å°: {size_mb:.2f}MB")

    async def get_supported_voices(self) -> Dict[str, Any]:
        """
        è·å–æ”¯æŒçš„è¯­éŸ³é€‰é¡¹
        
        Returns:
            åŒ…å«voiceså’Œdefaulté”®çš„å­—å…¸
        """
        try:
            logger.info("ğŸµ è·å–æ”¯æŒçš„è¯­éŸ³é€‰é¡¹")
            
            # è·å–TTSæœåŠ¡æ”¯æŒçš„è¯­éŸ³
            tts_voices = {}
            if hasattr(self.tts_service, 'get_supported_voices'):
                tts_voices = self.tts_service.get_supported_voices()
            
            # åˆå¹¶æ‰€æœ‰å¼•æ“çš„è¯­éŸ³é€‰é¡¹
            all_voices = {}
            default_voice = "nova"  # é»˜è®¤è¯­éŸ³
            
            # ä»é…ç½®è·å–é»˜è®¤è¯­éŸ³
            voice_config = config.get_voice_config()
            default_voice = voice_config.get("default_voice", "nova")
            
            # æ•´åˆEdge-TTSå¼•æ“çš„è¯­éŸ³
            if "edge-tts" in tts_voices:
                edge_voices = tts_voices["edge-tts"]
                for voice_id, description in edge_voices.items():
                    all_voices[voice_id] = {
                        "name": voice_id,
                        "description": description,
                        "engine": "edge-tts",
                        "language": "zh-CN" if not voice_id.endswith("_en") else "en-US",
                        "gender": self._detect_voice_gender(description),
                        "available": True
                    }
            
            # æ•´åˆPyttsx3å¼•æ“çš„è¯­éŸ³
            if "pyttsx3" in tts_voices:
                pyttsx3_voices = tts_voices["pyttsx3"]
                for voice_id, description in pyttsx3_voices.items():
                    if voice_id not in all_voices:  # é¿å…é‡å¤
                        all_voices[voice_id] = {
                            "name": voice_id,
                            "description": description,
                            "engine": "pyttsx3",
                            "language": "zh-CN",
                            "gender": self._detect_voice_gender(description),
                            "available": True
                        }
            
            # å¦‚æœæ²¡æœ‰ä»å¼•æ“è·å–åˆ°è¯­éŸ³ï¼Œæä¾›é»˜è®¤è¯­éŸ³é€‰é¡¹
            if not all_voices:
                all_voices = {
                    "nova": {
                        "name": "nova",
                        "description": "é»˜è®¤å¥³å£° - è‡ªç„¶äº²åˆ‡",
                        "engine": "system",
                        "language": "zh-CN",
                        "gender": "female",
                        "available": True
                    },
                    "echo": {
                        "name": "echo",
                        "description": "é»˜è®¤ç”·å£° - æ²‰ç¨³ä¸“ä¸š",
                        "engine": "system",
                        "language": "zh-CN",
                        "gender": "male",
                        "available": True
                    },
                    "alloy": {
                        "name": "alloy",
                        "description": "ä¸­æ€§å£°éŸ³ - æ¸…æ™°ä¸­æ€§",
                        "engine": "system",
                        "language": "zh-CN",
                        "gender": "neutral",
                        "available": True
                    }
                }
            
            # ç¡®ä¿é»˜è®¤è¯­éŸ³å­˜åœ¨
            if default_voice not in all_voices:
                default_voice = next(iter(all_voices.keys())) if all_voices else "nova"
            
            result = {
                "voices": all_voices,
                "default": default_voice,
                "total_count": len(all_voices),
                "engines": list(set(voice["engine"] for voice in all_voices.values())),
                "languages": list(set(voice["language"] for voice in all_voices.values()))
            }
            
            logger.info(f"âœ… è·å–è¯­éŸ³é€‰é¡¹æˆåŠŸ: {len(all_voices)} ä¸ªè¯­éŸ³, é»˜è®¤: {default_voice}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ è·å–è¯­éŸ³é€‰é¡¹å¤±è´¥: {e}")
            # è¿”å›æœ€åŸºæœ¬çš„é»˜è®¤è¯­éŸ³é€‰é¡¹
            return {
                "voices": {
                    "nova": {
                        "name": "nova",
                        "description": "é»˜è®¤è¯­éŸ³",
                        "engine": "fallback",
                        "language": "zh-CN",
                        "gender": "female",
                        "available": True
                    }
                },
                "default": "nova",
                "total_count": 1,
                "engines": ["fallback"],
                "languages": ["zh-CN"],
                "error": str(e)
            }
    
    def _detect_voice_gender(self, description: str) -> str:
        """
        æ ¹æ®æè¿°æ£€æµ‹è¯­éŸ³æ€§åˆ«
        
        Args:
            description: è¯­éŸ³æè¿°
            
        Returns:
            æ€§åˆ«: "male", "female", "neutral"
        """
        desc_lower = description.lower()
        
        # æ£€æµ‹å¥³æ€§å…³é”®è¯
        if any(keyword in desc_lower for keyword in ['female', 'å¥³', 'å¥³æ€§', 'å¥³å£°', 'aria', 'jenny', 'sara']):
            return "female"
        
        # æ£€æµ‹ç”·æ€§å…³é”®è¯
        if any(keyword in desc_lower for keyword in ['male', 'ç”·', 'ç”·æ€§', 'ç”·å£°', 'guy', 'davis', 'tony']):
            return "male"
        
        # æ£€æµ‹ä¸­æ€§å…³é”®è¯
        if any(keyword in desc_lower for keyword in ['neutral', 'ä¸­æ€§', 'alloy']):
            return "neutral"
        
        # é»˜è®¤æ ¹æ®åç§°åˆ¤æ–­
        if any(name in desc_lower for name in ['nova', 'aria', 'jenny', 'sara', 'æ™“', 'å°']):
            return "female"
        elif any(name in desc_lower for name in ['echo', 'onyx', 'guy', 'davis', 'tony', 'äº‘', 'ç”·']):
            return "male"
        
        return "neutral"


class VoiceInterviewer:
    """è¯­éŸ³é¢è¯•å®˜ç±»"""
    
    def __init__(self, speech_service: SpeechService):
        self.speech_service = speech_service
        voice_config = config.get_voice_config()
        self.interviewer_voice = voice_config["default_voice"]  # ä½¿ç”¨é…ç½®çš„é»˜è®¤å£°éŸ³
        self.speech_speed = voice_config["default_speed"]
        
    async def speak_question(self, question: str) -> bytes:
        """
        æœ—è¯»é¢è¯•é—®é¢˜
        
        Args:
            question: é—®é¢˜æ–‡æœ¬
            
        Returns:
            éŸ³é¢‘æ•°æ®
        """
        # ä¸ºé—®é¢˜æ·»åŠ é€‚å½“çš„è¯­è°ƒæç¤º
        formatted_question = self._format_question_for_speech(question)
        
        return await self.speech_service.text_to_speech(
            text=formatted_question,
            voice=self.interviewer_voice,
            speed=self.speech_speed
        )

    async def stream_speak_question(self, question: str) -> AsyncGenerator[bytes, None]:
        """
        æµå¼æœ—è¯»é¢è¯•é—®é¢˜
        
        Args:
            question: é—®é¢˜æ–‡æœ¬
            
        Yields:
            éŸ³é¢‘æ•°æ®å—
        """
        formatted_question = self._format_question_for_speech(question)
        
        async for chunk in self.speech_service.stream_text_to_speech(
            text=formatted_question,
            voice=self.interviewer_voice,
            speed=self.speech_speed
        ):
            yield chunk

    async def process_voice_answer(
        self, 
        audio_data: bytes,
        context: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†è¯­éŸ³å›ç­”
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # è½¬å½•è¯­éŸ³
            transcript_result = await self.speech_service.speech_to_text(
                audio_data, 
                prompt=context
            )
            
            # åˆ†æè¯­éŸ³ç‰¹å¾
            speech_analysis = await self.speech_service.analyze_speech_features(audio_data)
            
            return {
                "transcript": transcript_result,
                "speech_analysis": speech_analysis,
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"è¯­éŸ³ç­”æ¡ˆå¤„ç†å¤±è´¥: {e}")
            return {
                "error": str(e),
                "status": "error"
            }

    def _format_question_for_speech(self, question: str) -> str:
        """
        ä¸ºè¯­éŸ³åˆæˆæ ¼å¼åŒ–é—®é¢˜æ–‡æœ¬
        
        Args:
            question: åŸå§‹é—®é¢˜
            
        Returns:
            æ ¼å¼åŒ–åçš„é—®é¢˜
        """
        # æ·»åŠ é€‚å½“çš„åœé¡¿å’Œè¯­è°ƒ
        formatted = question.strip()
        
        # ç¡®ä¿ä»¥é—®å·ç»“å°¾
        if not formatted.endswith(('?', 'ï¼Ÿ')):
            formatted += "?"
        
        # ä¸ºè¾ƒé•¿çš„é—®é¢˜æ·»åŠ åœé¡¿
        if len(formatted) > 50:
            # åœ¨é€—å·åæ·»åŠ çŸ­åœé¡¿
            formatted = formatted.replace(',', ', ')
            formatted = formatted.replace('ï¼Œ', 'ï¼Œ ')
        
        return formatted

    def set_voice_config(self, voice: Optional[str] = None, speed: Optional[float] = None):
        """
        è®¾ç½®è¯­éŸ³é…ç½®
        
        Args:
            voice: å£°éŸ³ç±»å‹
            speed: è¯­é€Ÿ
        """
        if voice:
            self.interviewer_voice = voice
        if speed:
            self.speech_speed = max(0.25, min(4.0, speed))


# å…¨å±€å®ä¾‹
speech_service = SpeechService()
voice_interviewer = VoiceInterviewer(speech_service)

# å¯¼å‡ºå‡½æ•°ï¼ˆç”¨äºæµ‹è¯•å…¼å®¹ï¼‰
def get_client_manager():
    """è·å–å®¢æˆ·ç«¯ç®¡ç†å™¨ï¼ˆç”¨äºæµ‹è¯•å…¼å®¹ï¼‰"""
    from core.qwen_llama_client import get_client_manager
    return get_client_manager()

async def get_speech_service() -> SpeechService:
    """è·å–è¯­éŸ³æœåŠ¡å®ä¾‹"""
    return speech_service

# Export
__all__ = ["SpeechService", "VoiceInterviewer", "speech_service", "voice_interviewer", "get_speech_service", "get_client_manager"]